{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1e52f5",
   "metadata": {},
   "source": [
    "# Test of looping over $\\beta$-VAE to detect and classify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656a3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d22e804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Choosen device = cuda\n"
     ]
    }
   ],
   "source": [
    "from magnetics_diagnostic_analysis.project_vae.setting_vae import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c251617f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Torch version?  2.4.1+cu121\n",
      "Cuda?           True\n",
      "\n",
      "GPU number : 2\n",
      "GPU 0: Tesla T4\n",
      "GPU 1: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from magnetics_diagnostic_analysis.ml_tools.pytorch_device_selection import print_torch_info\n",
    "print_torch_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cd8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"vae\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9ccbb4",
   "metadata": {},
   "source": [
    "### 1. Create dataset and DataLoader\n",
    "\n",
    "I took the decision that one data sample will be : all the time values of one shot and for all diagnostics. It will be easy after, to reduce to one diagnostic only (It wouldn't habe been the case if we wanted to use all diagnostics for one timestep -> there reduce to one diagnostic just give us one number and that is to small).\n",
    "\n",
    "As all shots own different lenghts, we are going to use LSTM unit in entry of our VAE. This LSTM unit is combined with padded sequence and have masking behaviour.\n",
    "\n",
    "Thus, after the LSTM, we will have a constant size tensor (the LSTM hidden state) that we can use in our VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e6fffd",
   "metadata": {},
   "source": [
    "Consideration:\n",
    "\n",
    "We want our model to be robust to any different size during testing time.\n",
    "\n",
    "Thus, we are going to find the max_lenght for each batch size in the dataloader.\n",
    "\n",
    "And thanks to the two functions `pack_padded_sequence`, `pad_packed_sequence`, the LSTM is aware of the true lenght of each sequence and use masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9f65087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdc0f8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base rgba(0, 0, 0, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, white)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 15))\n",
       "  );\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, #111111)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 15))\n",
       "  );\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "  border: 2px solid transparent !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0) !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  border-color: var(--xr-background-color-row-odd);\n",
       "  margin-bottom: 0;\n",
       "  padding-top: 2px;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "  border-color: var(--xr-background-color-row-even);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  border-top: 2px dotted var(--xr-background-color);\n",
       "  padding-bottom: 20px !important;\n",
       "  padding-top: 10px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in + label,\n",
       ".xr-var-data-in + label,\n",
       ".xr-index-data-in + label {\n",
       "  padding: 0 1px;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-data > pre,\n",
       ".xr-index-data > pre,\n",
       ".xr-var-data > table > tbody > tr {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked + label > .xr-icon-file-text2,\n",
       ".xr-var-data-in:checked + label > .xr-icon-database,\n",
       ".xr-index-data-in:checked + label > .xr-icon-database {\n",
       "  color: var(--xr-font-color0);\n",
       "  filter: drop-shadow(1px 1px 5px var(--xr-font-color2));\n",
       "  stroke-width: 0.8px;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 10GB\n",
       "Dimensions:                                   (time: 12877819,\n",
       "                                               b_field_tor_probe_saddle_voltage_channel: 9,\n",
       "                                               b_field_pol_probe_obr_channel: 18,\n",
       "                                               b_field_pol_probe_ccbv_channel: 37,\n",
       "                                               flux_loop_channel: 14,\n",
       "                                               b_field_pol_probe_obv_channel: 17)\n",
       "Coordinates:\n",
       "  * b_field_tor_probe_saddle_voltage_channel  (b_field_tor_probe_saddle_voltage_channel) &lt;U15 540B ...\n",
       "  * time                                      (time) float64 103MB -0.0692 .....\n",
       "  * b_field_pol_probe_obr_channel             (b_field_pol_probe_obr_channel) &lt;U9 648B ...\n",
       "  * b_field_pol_probe_ccbv_channel            (b_field_pol_probe_ccbv_channel) &lt;U10 1kB ...\n",
       "  * flux_loop_channel                         (flux_loop_channel) &lt;U12 672B &#x27;...\n",
       "  * b_field_pol_probe_obv_channel             (b_field_pol_probe_obv_channel) &lt;U9 612B ...\n",
       "Data variables:\n",
       "    b_field_tor_probe_saddle_voltage          (time, b_field_tor_probe_saddle_voltage_channel) float64 927MB ...\n",
       "    b_field_pol_probe_obr_field               (time, b_field_pol_probe_obr_channel) float64 2GB ...\n",
       "    ip                                        (time) float64 103MB ...\n",
       "    b_field_pol_probe_ccbv_field              (time, b_field_pol_probe_ccbv_channel) float64 4GB ...\n",
       "    flux_loop_flux                            (time, flux_loop_channel) float64 1GB ...\n",
       "    b_field_pol_probe_obv_field               (time, b_field_pol_probe_obv_channel) float64 2GB ...\n",
       "    shot_index                                (time) int64 103MB ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-8bbeba2b-83a8-4d58-bb95-7c6911d82ba0' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-8bbeba2b-83a8-4d58-bb95-7c6911d82ba0' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 12877819</li><li><span class='xr-has-index'>b_field_tor_probe_saddle_voltage_channel</span>: 9</li><li><span class='xr-has-index'>b_field_pol_probe_obr_channel</span>: 18</li><li><span class='xr-has-index'>b_field_pol_probe_ccbv_channel</span>: 37</li><li><span class='xr-has-index'>flux_loop_channel</span>: 14</li><li><span class='xr-has-index'>b_field_pol_probe_obv_channel</span>: 17</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-1d86d359-e493-44af-a324-341df5254621' class='xr-section-summary-in' type='checkbox'  checked><label for='section-1d86d359-e493-44af-a324-341df5254621' class='xr-section-summary' >Coordinates: <span>(6)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>b_field_tor_probe_saddle_voltage_channel</span></div><div class='xr-var-dims'>(b_field_tor_probe_saddle_voltage_channel)</div><div class='xr-var-dtype'>&lt;U15</div><div class='xr-var-preview xr-preview'>&#x27;XMB_SAD/OUT/M01&#x27; ... &#x27;XMB_SAD/O...</div><input id='attrs-45fd2acc-98cf-442f-af02-46a6c19ee1b9' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-45fd2acc-98cf-442f-af02-46a6c19ee1b9' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e0615f55-d487-4bcd-aa72-53c0ba733380' class='xr-var-data-in' type='checkbox'><label for='data-e0615f55-d487-4bcd-aa72-53c0ba733380' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;XMB_SAD/OUT/M01&#x27;, &#x27;XMB_SAD/OUT/M02&#x27;, &#x27;XMB_SAD/OUT/M03&#x27;,\n",
       "       &#x27;XMB_SAD/OUT/M04&#x27;, &#x27;XMB_SAD/OUT/M05&#x27;, &#x27;XMB_SAD/OUT/M06&#x27;,\n",
       "       &#x27;XMB_SAD/OUT/M07&#x27;, &#x27;XMB_SAD/OUT/M08&#x27;, &#x27;XMB_SAD/OUT/M09&#x27;], dtype=&#x27;&lt;U15&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-0.0692 -0.06895 ... 0.3918 0.3921</div><input id='attrs-80effa20-f838-44cc-98e9-dc19ba43dde2' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-80effa20-f838-44cc-98e9-dc19ba43dde2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ba9b1c3a-3d0e-4e63-945e-08f7fb539cbc' class='xr-var-data-in' type='checkbox'><label for='data-ba9b1c3a-3d0e-4e63-945e-08f7fb539cbc' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>s</dd></dl></div><div class='xr-var-data'><pre>array([-0.0692 , -0.06895, -0.0687 , ...,  0.3916 ,  0.39185,  0.3921 ])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>b_field_pol_probe_obr_channel</span></div><div class='xr-var-dims'>(b_field_pol_probe_obr_channel)</div><div class='xr-var-dtype'>&lt;U9</div><div class='xr-var-preview xr-preview'>&#x27;AMB_OBR01&#x27; ... &#x27;AMB_OBR18&#x27;</div><input id='attrs-3efd68a5-d909-4a87-a9f9-d7053b70381a' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-3efd68a5-d909-4a87-a9f9-d7053b70381a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0829ed9a-fe04-4011-93df-3cc32a444bdb' class='xr-var-data-in' type='checkbox'><label for='data-0829ed9a-fe04-4011-93df-3cc32a444bdb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;AMB_OBR01&#x27;, &#x27;AMB_OBR02&#x27;, &#x27;AMB_OBR03&#x27;, &#x27;AMB_OBR04&#x27;, &#x27;AMB_OBR05&#x27;,\n",
       "       &#x27;AMB_OBR06&#x27;, &#x27;AMB_OBR07&#x27;, &#x27;AMB_OBR08&#x27;, &#x27;AMB_OBR09&#x27;, &#x27;AMB_OBR10&#x27;,\n",
       "       &#x27;AMB_OBR11&#x27;, &#x27;AMB_OBR12&#x27;, &#x27;AMB_OBR13&#x27;, &#x27;AMB_OBR14&#x27;, &#x27;AMB_OBR15&#x27;,\n",
       "       &#x27;AMB_OBR16&#x27;, &#x27;AMB_OBR17&#x27;, &#x27;AMB_OBR18&#x27;], dtype=&#x27;&lt;U9&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>b_field_pol_probe_ccbv_channel</span></div><div class='xr-var-dims'>(b_field_pol_probe_ccbv_channel)</div><div class='xr-var-dtype'>&lt;U10</div><div class='xr-var-preview xr-preview'>&#x27;AMB_CCBV01&#x27; ... &#x27;AMB_CCBV40&#x27;</div><input id='attrs-4e0cb173-d835-4212-a0ba-6ce335aca09b' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-4e0cb173-d835-4212-a0ba-6ce335aca09b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e0e69e07-2ab7-401f-8866-f5ee4e14c645' class='xr-var-data-in' type='checkbox'><label for='data-e0e69e07-2ab7-401f-8866-f5ee4e14c645' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;AMB_CCBV01&#x27;, &#x27;AMB_CCBV02&#x27;, &#x27;AMB_CCBV03&#x27;, &#x27;AMB_CCBV04&#x27;, &#x27;AMB_CCBV05&#x27;,\n",
       "       &#x27;AMB_CCBV06&#x27;, &#x27;AMB_CCBV07&#x27;, &#x27;AMB_CCBV08&#x27;, &#x27;AMB_CCBV09&#x27;, &#x27;AMB_CCBV11&#x27;,\n",
       "       &#x27;AMB_CCBV12&#x27;, &#x27;AMB_CCBV14&#x27;, &#x27;AMB_CCBV15&#x27;, &#x27;AMB_CCBV16&#x27;, &#x27;AMB_CCBV17&#x27;,\n",
       "       &#x27;AMB_CCBV18&#x27;, &#x27;AMB_CCBV19&#x27;, &#x27;AMB_CCBV20&#x27;, &#x27;AMB_CCBV21&#x27;, &#x27;AMB_CCBV23&#x27;,\n",
       "       &#x27;AMB_CCBV24&#x27;, &#x27;AMB_CCBV25&#x27;, &#x27;AMB_CCBV26&#x27;, &#x27;AMB_CCBV27&#x27;, &#x27;AMB_CCBV28&#x27;,\n",
       "       &#x27;AMB_CCBV29&#x27;, &#x27;AMB_CCBV30&#x27;, &#x27;AMB_CCBV31&#x27;, &#x27;AMB_CCBV32&#x27;, &#x27;AMB_CCBV33&#x27;,\n",
       "       &#x27;AMB_CCBV34&#x27;, &#x27;AMB_CCBV35&#x27;, &#x27;AMB_CCBV36&#x27;, &#x27;AMB_CCBV37&#x27;, &#x27;AMB_CCBV38&#x27;,\n",
       "       &#x27;AMB_CCBV39&#x27;, &#x27;AMB_CCBV40&#x27;], dtype=&#x27;&lt;U10&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>flux_loop_channel</span></div><div class='xr-var-dims'>(flux_loop_channel)</div><div class='xr-var-dtype'>&lt;U12</div><div class='xr-var-preview xr-preview'>&#x27;AMB_FL/CC03&#x27; ... &#x27;AMB_FL/P5U/1&#x27;</div><input id='attrs-085fdbce-d0f9-49dc-89c9-200a50dd366f' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-085fdbce-d0f9-49dc-89c9-200a50dd366f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-6dc820e0-51c5-4100-af98-b743a0be1d58' class='xr-var-data-in' type='checkbox'><label for='data-6dc820e0-51c5-4100-af98-b743a0be1d58' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;AMB_FL/CC03&#x27;, &#x27;AMB_FL/CC04&#x27;, &#x27;AMB_FL/CC05&#x27;, &#x27;AMB_FL/CC07&#x27;,\n",
       "       &#x27;AMB_FL/CC09&#x27;, &#x27;AMB_FL/P3L/4&#x27;, &#x27;AMB_FL/P3U/1&#x27;, &#x27;AMB_FL/P3U/4&#x27;,\n",
       "       &#x27;AMB_FL/P4L/1&#x27;, &#x27;AMB_FL/P4L/4&#x27;, &#x27;AMB_FL/P4U/4&#x27;, &#x27;AMB_FL/P5L/1&#x27;,\n",
       "       &#x27;AMB_FL/P5L/4&#x27;, &#x27;AMB_FL/P5U/1&#x27;], dtype=&#x27;&lt;U12&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>b_field_pol_probe_obv_channel</span></div><div class='xr-var-dims'>(b_field_pol_probe_obv_channel)</div><div class='xr-var-dtype'>&lt;U9</div><div class='xr-var-preview xr-preview'>&#x27;AMB_OBV01&#x27; ... &#x27;AMB_OBV18&#x27;</div><input id='attrs-b00e8777-3999-46af-b9ef-f797d2aea3fd' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-b00e8777-3999-46af-b9ef-f797d2aea3fd' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-272f382e-bd1a-4eb9-9689-ce7f86774d12' class='xr-var-data-in' type='checkbox'><label for='data-272f382e-bd1a-4eb9-9689-ce7f86774d12' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;AMB_OBV01&#x27;, &#x27;AMB_OBV02&#x27;, &#x27;AMB_OBV03&#x27;, &#x27;AMB_OBV04&#x27;, &#x27;AMB_OBV05&#x27;,\n",
       "       &#x27;AMB_OBV06&#x27;, &#x27;AMB_OBV07&#x27;, &#x27;AMB_OBV08&#x27;, &#x27;AMB_OBV09&#x27;, &#x27;AMB_OBV11&#x27;,\n",
       "       &#x27;AMB_OBV12&#x27;, &#x27;AMB_OBV13&#x27;, &#x27;AMB_OBV14&#x27;, &#x27;AMB_OBV15&#x27;, &#x27;AMB_OBV16&#x27;,\n",
       "       &#x27;AMB_OBV17&#x27;, &#x27;AMB_OBV18&#x27;], dtype=&#x27;&lt;U9&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-7ebd0fe8-2612-4135-9b7d-05dcb0da43a8' class='xr-section-summary-in' type='checkbox'  checked><label for='section-7ebd0fe8-2612-4135-9b7d-05dcb0da43a8' class='xr-section-summary' >Data variables: <span>(7)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>b_field_tor_probe_saddle_voltage</span></div><div class='xr-var-dims'>(time, b_field_tor_probe_saddle_voltage_channel)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-e273a31c-cb9e-4213-b453-966528a40021' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-e273a31c-cb9e-4213-b453-966528a40021' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-62228b0b-faa9-49ca-bee6-d2ab136c1b1c' class='xr-var-data-in' type='checkbox'><label for='data-62228b0b-faa9-49ca-bee6-d2ab136c1b1c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd></dd><dt><span>imas :</span></dt><dd>magnetics.b_field_tor_probe[:].voltage.data</dd><dt><span>name :</span></dt><dd>b_field_tor_probe_saddle_voltage</dd><dt><span>uda_name :</span></dt><dd>XMB_SAD/OUT/M01</dd><dt><span>units :</span></dt><dd>V</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[115900371 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>b_field_pol_probe_obr_field</span></div><div class='xr-var-dims'>(time, b_field_pol_probe_obr_channel)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-6ff2998d-5024-46af-97e7-7462b00c5272' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-6ff2998d-5024-46af-97e7-7462b00c5272' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-22057a0b-8612-4d67-898c-c7cec8af3964' class='xr-var-data-in' type='checkbox'><label for='data-22057a0b-8612-4d67-898c-c7cec8af3964' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd>Outer Br array</dd><dt><span>imas :</span></dt><dd>magnetics.b_field_pol_probe[:].field.data</dd><dt><span>label :</span></dt><dd>OBR01</dd><dt><span>name :</span></dt><dd>b_field_pol_probe_obr_field</dd><dt><span>uda_name :</span></dt><dd>AMB_OBR01</dd><dt><span>units :</span></dt><dd>T</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[231800742 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>ip</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-96318a05-abbf-4fcf-8e7c-2c24b0054148' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-96318a05-abbf-4fcf-8e7c-2c24b0054148' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c3892b4d-fd8b-452d-a618-7d79ed8626ba' class='xr-var-data-in' type='checkbox'><label for='data-c3892b4d-fd8b-452d-a618-7d79ed8626ba' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd></dd><dt><span>imas :</span></dt><dd>magnetics.ip[:].data</dd><dt><span>label :</span></dt><dd>Plasma Current</dd><dt><span>name :</span></dt><dd>ip</dd><dt><span>uda_name :</span></dt><dd>AMC_PLASMA CURRENT</dd><dt><span>units :</span></dt><dd>A</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[12877819 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>b_field_pol_probe_ccbv_field</span></div><div class='xr-var-dims'>(time, b_field_pol_probe_ccbv_channel)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-ddfd6600-5420-46c2-9780-9a9a3d6b5cd6' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-ddfd6600-5420-46c2-9780-9a9a3d6b5cd6' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-ca924f7b-c58f-4ff9-ae29-e765ac3363eb' class='xr-var-data-in' type='checkbox'><label for='data-ca924f7b-c58f-4ff9-ae29-e765ac3363eb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd>Centre column Bv array</dd><dt><span>imas :</span></dt><dd>magnetics.b_field_pol_probe[:].field.data</dd><dt><span>label :</span></dt><dd>CCBV01</dd><dt><span>name :</span></dt><dd>b_field_pol_probe_ccbv_field</dd><dt><span>uda_name :</span></dt><dd>AMB_CCBV01</dd><dt><span>units :</span></dt><dd>T</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[476479303 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>flux_loop_flux</span></div><div class='xr-var-dims'>(time, flux_loop_channel)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-cbe35b8d-01b6-42fa-b606-54aa9d5f1627' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-cbe35b8d-01b6-42fa-b606-54aa9d5f1627' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bec01553-a02e-4a90-8160-dd33dadb2b1f' class='xr-var-data-in' type='checkbox'><label for='data-bec01553-a02e-4a90-8160-dd33dadb2b1f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd></dd><dt><span>imas :</span></dt><dd>magnetics.flux_loop[:].flux.data</dd><dt><span>label :</span></dt><dd>FL/CC03</dd><dt><span>name :</span></dt><dd>flux_loop_flux</dd><dt><span>uda_name :</span></dt><dd>AMB_FL/CC03</dd><dt><span>units :</span></dt><dd>Wb</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[180289466 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>b_field_pol_probe_obv_field</span></div><div class='xr-var-dims'>(time, b_field_pol_probe_obv_channel)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-b551bf80-86a1-4568-af60-87b997dcea16' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b551bf80-86a1-4568-af60-87b997dcea16' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-dd2313a0-5ab7-428d-842d-82b9d1034e41' class='xr-var-data-in' type='checkbox'><label for='data-dd2313a0-5ab7-428d-842d-82b9d1034e41' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd>Outer Bv array</dd><dt><span>imas :</span></dt><dd>magnetics.b_field_pol_probe[:].field.data</dd><dt><span>label :</span></dt><dd>OBV01</dd><dt><span>name :</span></dt><dd>b_field_pol_probe_obv_field</dd><dt><span>uda_name :</span></dt><dd>AMB_OBV01</dd><dt><span>units :</span></dt><dd>T</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[218922923 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>shot_index</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-f8ea1a06-69ac-4467-990a-8347c76f5a14' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f8ea1a06-69ac-4467-990a-8347c76f5a14' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-2efdd719-e32f-49cf-97f5-980505a09f01' class='xr-var-data-in' type='checkbox'><label for='data-2efdd719-e32f-49cf-97f5-980505a09f01' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[12877819 values with dtype=int64]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-b209732b-cb11-4be5-909a-c807f1db15fd' class='xr-section-summary-in' type='checkbox'  ><label for='section-b209732b-cb11-4be5-909a-c807f1db15fd' class='xr-section-summary' >Indexes: <span>(6)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>b_field_tor_probe_saddle_voltage_channel</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-7a9bebfc-a29a-4131-b9ac-f620843ed018' class='xr-index-data-in' type='checkbox'/><label for='index-7a9bebfc-a29a-4131-b9ac-f620843ed018' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;XMB_SAD/OUT/M01&#x27;, &#x27;XMB_SAD/OUT/M02&#x27;, &#x27;XMB_SAD/OUT/M03&#x27;,\n",
       "       &#x27;XMB_SAD/OUT/M04&#x27;, &#x27;XMB_SAD/OUT/M05&#x27;, &#x27;XMB_SAD/OUT/M06&#x27;,\n",
       "       &#x27;XMB_SAD/OUT/M07&#x27;, &#x27;XMB_SAD/OUT/M08&#x27;, &#x27;XMB_SAD/OUT/M09&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;b_field_tor_probe_saddle_voltage_channel&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-63d90bb1-1e68-45e5-8c16-1cb702cf35e3' class='xr-index-data-in' type='checkbox'/><label for='index-63d90bb1-1e68-45e5-8c16-1cb702cf35e3' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-0.06920000165700912, -0.06895000165700912, -0.06870000165700912,\n",
       "       -0.06845000165700912, -0.06820000165700912, -0.06795000165700912,\n",
       "       -0.06770000165700912, -0.06745000165700912, -0.06720000165700912,\n",
       "       -0.06695000165700912,\n",
       "       ...\n",
       "           0.38984995174408,     0.39009995174408,  0.39034995174408005,\n",
       "           0.39059995174408,     0.39084995174408,     0.39109995174408,\n",
       "        0.39134995174408005,     0.39159995174408,     0.39184995174408,\n",
       "           0.39209995174408],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;time&#x27;, length=12877819))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>b_field_pol_probe_obr_channel</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-71923368-6057-4768-a067-98a3cbfdfd75' class='xr-index-data-in' type='checkbox'/><label for='index-71923368-6057-4768-a067-98a3cbfdfd75' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;AMB_OBR01&#x27;, &#x27;AMB_OBR02&#x27;, &#x27;AMB_OBR03&#x27;, &#x27;AMB_OBR04&#x27;, &#x27;AMB_OBR05&#x27;,\n",
       "       &#x27;AMB_OBR06&#x27;, &#x27;AMB_OBR07&#x27;, &#x27;AMB_OBR08&#x27;, &#x27;AMB_OBR09&#x27;, &#x27;AMB_OBR10&#x27;,\n",
       "       &#x27;AMB_OBR11&#x27;, &#x27;AMB_OBR12&#x27;, &#x27;AMB_OBR13&#x27;, &#x27;AMB_OBR14&#x27;, &#x27;AMB_OBR15&#x27;,\n",
       "       &#x27;AMB_OBR16&#x27;, &#x27;AMB_OBR17&#x27;, &#x27;AMB_OBR18&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;b_field_pol_probe_obr_channel&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>b_field_pol_probe_ccbv_channel</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-306edfaa-fc7a-45c1-a3f2-dca9fd531ed1' class='xr-index-data-in' type='checkbox'/><label for='index-306edfaa-fc7a-45c1-a3f2-dca9fd531ed1' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;AMB_CCBV01&#x27;, &#x27;AMB_CCBV02&#x27;, &#x27;AMB_CCBV03&#x27;, &#x27;AMB_CCBV04&#x27;, &#x27;AMB_CCBV05&#x27;,\n",
       "       &#x27;AMB_CCBV06&#x27;, &#x27;AMB_CCBV07&#x27;, &#x27;AMB_CCBV08&#x27;, &#x27;AMB_CCBV09&#x27;, &#x27;AMB_CCBV11&#x27;,\n",
       "       &#x27;AMB_CCBV12&#x27;, &#x27;AMB_CCBV14&#x27;, &#x27;AMB_CCBV15&#x27;, &#x27;AMB_CCBV16&#x27;, &#x27;AMB_CCBV17&#x27;,\n",
       "       &#x27;AMB_CCBV18&#x27;, &#x27;AMB_CCBV19&#x27;, &#x27;AMB_CCBV20&#x27;, &#x27;AMB_CCBV21&#x27;, &#x27;AMB_CCBV23&#x27;,\n",
       "       &#x27;AMB_CCBV24&#x27;, &#x27;AMB_CCBV25&#x27;, &#x27;AMB_CCBV26&#x27;, &#x27;AMB_CCBV27&#x27;, &#x27;AMB_CCBV28&#x27;,\n",
       "       &#x27;AMB_CCBV29&#x27;, &#x27;AMB_CCBV30&#x27;, &#x27;AMB_CCBV31&#x27;, &#x27;AMB_CCBV32&#x27;, &#x27;AMB_CCBV33&#x27;,\n",
       "       &#x27;AMB_CCBV34&#x27;, &#x27;AMB_CCBV35&#x27;, &#x27;AMB_CCBV36&#x27;, &#x27;AMB_CCBV37&#x27;, &#x27;AMB_CCBV38&#x27;,\n",
       "       &#x27;AMB_CCBV39&#x27;, &#x27;AMB_CCBV40&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;b_field_pol_probe_ccbv_channel&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>flux_loop_channel</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-5a4aa363-c64e-42da-9b29-548bde1a38cc' class='xr-index-data-in' type='checkbox'/><label for='index-5a4aa363-c64e-42da-9b29-548bde1a38cc' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;AMB_FL/CC03&#x27;, &#x27;AMB_FL/CC04&#x27;, &#x27;AMB_FL/CC05&#x27;, &#x27;AMB_FL/CC07&#x27;,\n",
       "       &#x27;AMB_FL/CC09&#x27;, &#x27;AMB_FL/P3L/4&#x27;, &#x27;AMB_FL/P3U/1&#x27;, &#x27;AMB_FL/P3U/4&#x27;,\n",
       "       &#x27;AMB_FL/P4L/1&#x27;, &#x27;AMB_FL/P4L/4&#x27;, &#x27;AMB_FL/P4U/4&#x27;, &#x27;AMB_FL/P5L/1&#x27;,\n",
       "       &#x27;AMB_FL/P5L/4&#x27;, &#x27;AMB_FL/P5U/1&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;flux_loop_channel&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>b_field_pol_probe_obv_channel</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-c95c42ad-8243-474b-a748-3f5f28279874' class='xr-index-data-in' type='checkbox'/><label for='index-c95c42ad-8243-474b-a748-3f5f28279874' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;AMB_OBV01&#x27;, &#x27;AMB_OBV02&#x27;, &#x27;AMB_OBV03&#x27;, &#x27;AMB_OBV04&#x27;, &#x27;AMB_OBV05&#x27;,\n",
       "       &#x27;AMB_OBV06&#x27;, &#x27;AMB_OBV07&#x27;, &#x27;AMB_OBV08&#x27;, &#x27;AMB_OBV09&#x27;, &#x27;AMB_OBV11&#x27;,\n",
       "       &#x27;AMB_OBV12&#x27;, &#x27;AMB_OBV13&#x27;, &#x27;AMB_OBV14&#x27;, &#x27;AMB_OBV15&#x27;, &#x27;AMB_OBV16&#x27;,\n",
       "       &#x27;AMB_OBV17&#x27;, &#x27;AMB_OBV18&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;b_field_pol_probe_obv_channel&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-bbc12275-cd15-4463-b464-2a97d0833307' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-bbc12275-cd15-4463-b464-2a97d0833307' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 10GB\n",
       "Dimensions:                                   (time: 12877819,\n",
       "                                               b_field_tor_probe_saddle_voltage_channel: 9,\n",
       "                                               b_field_pol_probe_obr_channel: 18,\n",
       "                                               b_field_pol_probe_ccbv_channel: 37,\n",
       "                                               flux_loop_channel: 14,\n",
       "                                               b_field_pol_probe_obv_channel: 17)\n",
       "Coordinates:\n",
       "  * b_field_tor_probe_saddle_voltage_channel  (b_field_tor_probe_saddle_voltage_channel) <U15 540B ...\n",
       "  * time                                      (time) float64 103MB -0.0692 .....\n",
       "  * b_field_pol_probe_obr_channel             (b_field_pol_probe_obr_channel) <U9 648B ...\n",
       "  * b_field_pol_probe_ccbv_channel            (b_field_pol_probe_ccbv_channel) <U10 1kB ...\n",
       "  * flux_loop_channel                         (flux_loop_channel) <U12 672B '...\n",
       "  * b_field_pol_probe_obv_channel             (b_field_pol_probe_obv_channel) <U9 612B ...\n",
       "Data variables:\n",
       "    b_field_tor_probe_saddle_voltage          (time, b_field_tor_probe_saddle_voltage_channel) float64 927MB ...\n",
       "    b_field_pol_probe_obr_field               (time, b_field_pol_probe_obr_channel) float64 2GB ...\n",
       "    ip                                        (time) float64 103MB ...\n",
       "    b_field_pol_probe_ccbv_field              (time, b_field_pol_probe_ccbv_channel) float64 4GB ...\n",
       "    flux_loop_flux                            (time, flux_loop_channel) float64 1GB ...\n",
       "    b_field_pol_probe_obv_field               (time, b_field_pol_probe_obv_channel) float64 2GB ...\n",
       "    shot_index                                (time) int64 103MB ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path().absolute().parent.parent / \"data/preprocessed/mscred/data_magnetics_mscred_cleaned.nc\"\n",
    "data_all = xr.open_dataset(path)\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0c26f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2084, 1989, 2230, ..., 3153, 2089, 1947])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_seq_length(data: xr.Dataset) -> np.ndarray:\n",
    "    # Find the length of each sequence in the dataset\n",
    "    seq_indices = data['shot_index'].values\n",
    "    return np.bincount(seq_indices)\n",
    "\n",
    "lengths = find_seq_length(data_all)\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8628536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data: xr.Dataset, n_var_to_keep: int = 4, n_subsample: int = 10):\n",
    "        # Group data by shot_index\n",
    "        self.shot_indices = data['shot_index'].values\n",
    "        self.unique_shots = np.unique(self.shot_indices)\n",
    "        \n",
    "        # Precompute sequences for each shot index\n",
    "        self.sequences = {}\n",
    "        for shot in self.unique_shots:\n",
    "            mask = self.shot_indices == shot\n",
    "            shot_data = []\n",
    "            for var in data.data_vars:\n",
    "                if var == 'shot_index':\n",
    "                    continue\n",
    "                if data[var].ndim == 1:\n",
    "                    var_data = data[var].values[mask][:, np.newaxis]\n",
    "                else:\n",
    "                    var_data = data[var].values[mask]\n",
    "                    if var_data.shape[1] > n_var_to_keep:\n",
    "                        var_data = var_data[:, :n_var_to_keep]\n",
    "                var_data = var_data[::n_subsample]\n",
    "                shot_data.append(var_data)\n",
    "            self.sequences[shot] = np.concatenate(shot_data, axis=1)      # axis=1 => along features dimension\n",
    "        \n",
    "        self.lengths = {shot: len(self.sequences[shot]) for shot in self.unique_shots}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_shots)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        shot = self.unique_shots[idx]\n",
    "        return self.sequences[shot], self.lengths[shot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4bbaf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(\n",
    "    data: xr.Dataset,\n",
    "    set_separation: int = 12000,\n",
    ") -> tuple[Dataset]:\n",
    "    \"\"\"\n",
    "    Create train, validation and test data loaders from time series data\n",
    "    \n",
    "    Args:\n",
    "        data: xarray Dataset with shot_index variable\n",
    "        batch_size: batch size for data loaders\n",
    "        set_separation: boundarie between train and test sets\n",
    "        device: device to load data on\n",
    "    \n",
    "    Returns:\n",
    "        train_loader, valid_loader, test_loader: DataLoader objects\n",
    "    \"\"\"\n",
    "    # Get shot indices\n",
    "    shot_indices = data['shot_index'].values\n",
    "    unique_shots = np.unique(shot_indices)\n",
    "\n",
    "    # Find the time index where each shot starts\n",
    "    shot_start_times = {}\n",
    "    real_test_end = config.DATA_NUMBER\n",
    "    for shot in unique_shots:\n",
    "        start_idx = np.where(shot_indices == shot)[0][0]\n",
    "        shot_start_times[shot] = start_idx\n",
    "        if start_idx > real_test_end:\n",
    "            break\n",
    "\n",
    "    # Split shots into sets based on the set_separation values but also their start time\n",
    "    train_end= set_separation\n",
    "    test_shots = [shot for shot in unique_shots[:len(shot_start_times)] if real_test_end > shot_start_times[shot] >= train_end][:-1]    # [:-1] to exclude last incomplete shot\n",
    "    # Get real start and end times for each split: preserving shots integrity\n",
    "    real_test_start = shot_start_times[np.min(test_shots)]\n",
    "\n",
    "    # Create datasets for each split\n",
    "    train_dataset = TimeSeriesDataset(data.isel(time=slice(0, real_test_start)))\n",
    "    test_dataset = TimeSeriesDataset(data.isel(time=slice(real_test_start, real_test_end)))\n",
    "    \n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764de3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = create_datasets(data_all, set_separation=config.SET_SEPARATION)\n",
    "\n",
    "print(\"Training set size:\", len(train_set))\n",
    "print(\"Testing set size:\", len(test_set))\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c3ee387",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = config.DIR_PREPROCESSED_DATA / f\"dataset_magnetics_vae_train.pt\"\n",
    "path_test = config.DIR_PREPROCESSED_DATA / f\"dataset_magnetics_vae_test.pt\"\n",
    "if not path_train.exists():\n",
    "    torch.save(train_set, path_train)\n",
    "    print(f\"Saved dataset to {path_train}\")\n",
    "if not path_test.exists():\n",
    "    torch.save(test_set, path_test)\n",
    "    print(f\"Saved dataset to {path_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1771412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2229578/1740512887.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_set = torch.load(path_train)\n",
      "/tmp/ipykernel_2229578/1740512887.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_set = torch.load(path_test)\n"
     ]
    }
   ],
   "source": [
    "path_train = config.DIR_PREPROCESSED_DATA / f\"dataset_magnetics_vae_train.pt\"\n",
    "path_test = config.DIR_PREPROCESSED_DATA / f\"dataset_magnetics_vae_test.pt\"\n",
    "train_set = torch.load(path_train)\n",
    "test_set = torch.load(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e712bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences_smartly(batch):\n",
    "    \"\"\"Custom collate function to pad sequences to max length in batch\"\"\"\n",
    "    sequences, lengths = zip(*batch)\n",
    "    \n",
    "    # Convert sequences to tensors\n",
    "    sequence_tensors = [torch.from_numpy(seq).float() for seq in sequences]\n",
    "    padded_sequences = pad_sequence(\n",
    "        sequence_tensors, \n",
    "        batch_first=True, \n",
    "        padding_value=0.0\n",
    "    )\n",
    "    length_tensor = torch.tensor(lengths, dtype=torch.long)\n",
    "    \n",
    "    return padded_sequences, length_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed95bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(\n",
    "    train_dataset: Dataset,\n",
    "    test_dataset: Dataset,\n",
    "    batch_size: int = 32,\n",
    "    collate_fn: callable = None\n",
    ") -> tuple[DataLoader]:\n",
    "    \"\"\"\n",
    "    Create data loaders for training and testing\n",
    "\n",
    "    Args:\n",
    "        train_dataset: Dataset for training\n",
    "        test_dataset: Dataset for testing\n",
    "        batch_size: Batch size for data loaders\n",
    "        collate_fn: Custom collate function\n",
    "\n",
    "    Returns:\n",
    "        train_loader, test_loader: DataLoader objects\n",
    "    \"\"\"\n",
    "    # Create DataLoaders with custom collate function\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        drop_last=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37e9c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = create_data_loaders(\n",
    "    train_dataset=train_set,\n",
    "    test_dataset=test_set,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    collate_fn=pad_sequences_smartly\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf40544d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_loader: 368\n",
      "torch.Size([10, 248, 21])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train_loader:\", len(train_loader))\n",
    "\n",
    "print(next(iter(train_loader))[0].shape)  # Get the first batch: data\n",
    "print(next(iter(train_loader))[1].shape)  # Get the first batch: lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29daf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4061920d",
   "metadata": {},
   "source": [
    "## 2. Model LSTM-$\\beta$-VAE implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4bd66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"Embedding dimension must be divisible by number of heads\"\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        \n",
    "        # Projection layers for queries, keys and values\n",
    "        self.q_proj = nn.Linear(input_dim, embed_dim)\n",
    "        self.k_proj = nn.Linear(input_dim, embed_dim)\n",
    "        self.v_proj = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "        self.output_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = np.sqrt(self.head_dim)\n",
    "        \n",
    "    def forward(self, query, key, value, key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        query: [batch_size, query_len, input_dim]\n",
    "        key: [batch_size, key_len, input_dim]\n",
    "        value: [batch_size, value_len, input_dim]\n",
    "        key_padding_mask: [batch_size, key_len] (True for padding positions)\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "        query_len = query.size(1)\n",
    "        key_len = key.size(1)\n",
    "        \n",
    "        # Project queries, keys and values\n",
    "        Q = self.q_proj(query)  # [batch_size, query_len, embed_dim]\n",
    "        K = self.k_proj(key)    # [batch_size, key_len, embed_dim]\n",
    "        V = self.v_proj(value)  # [batch_size, value_len, embed_dim]\n",
    "        \n",
    "        # Reshape for multi-head attention\n",
    "        Q = Q.view(batch_size, query_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(batch_size, key_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(batch_size, key_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Calculate attention scores\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale  # [batch_size, num_heads, query_len, key_len]\n",
    "        \n",
    "        # Apply mask if provided\n",
    "        if key_padding_mask is not None:\n",
    "            # Expand mask to [batch_size, num_heads, query_len, key_len]\n",
    "            mask = key_padding_mask.unsqueeze(1).unsqueeze(2).expand(-1, self.num_heads, query_len, -1)\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attn_weights = nn.functional.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        attn_output = torch.matmul(attn_weights, V)  # [batch_size, num_heads, query_len, head_dim]\n",
    "        \n",
    "        # Concatenate heads and put through final linear layer\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, query_len, self.embed_dim)\n",
    "        attn_output = self.output_proj(attn_output)\n",
    "        \n",
    "        return attn_output, attn_weights\n",
    "    \n",
    "class MultiHeadAttention2(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        \n",
    "        self.q_proj = nn.Linear(dim, dim)\n",
    "        self.k_proj = nn.Linear(dim, dim)\n",
    "        self.v_proj = nn.Linear(dim, dim)\n",
    "        self.out_proj = nn.Linear(dim, dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # Projections linéaires\n",
    "        Q = self.q_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        K = self.k_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        V = self.v_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Calcul d'attention par tête\n",
    "        scores = torch.einsum('bqhd,bkhd->bhqk', Q, K) / math.sqrt(self.head_dim)\n",
    "        attention = torch.softmax(scores, dim=-1)\n",
    "        out = torch.einsum('bhqk,bkhd->bqhd', attention, V)\n",
    "        \n",
    "        # Concaténation et projection finale\n",
    "        out = out.contiguous().view(batch_size, seq_len, -1)\n",
    "        return self.out_proj(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be1dbf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeAttentionEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Attention sur la sortie LSTM\n",
    "        self.attention = MultiHeadAttention(\n",
    "            input_dim=hidden_dim * 2,\n",
    "            embed_dim=hidden_dim * 2, \n",
    "            num_heads=num_heads\n",
    "        )\n",
    "        \n",
    "        # Couches pour produire mean et logvar\n",
    "        self.to_mean = nn.Linear(hidden_dim * 2, latent_dim)\n",
    "        self.to_logvar = nn.Linear(hidden_dim * 2, latent_dim)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        # 1. LSTM\n",
    "        packed_input = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        # 2. Masque pour l'attention\n",
    "        mask = torch.arange(x.size(1), device=x.device)[None, :] >= lengths[:, None]\n",
    "        \n",
    "        # 3. Auto-attention sur la sortie LSTM\n",
    "        attn_output, attn_weights = self.attention(\n",
    "            query=lstm_output, \n",
    "            key=lstm_output, \n",
    "            value=lstm_output,\n",
    "            key_padding_mask=mask\n",
    "        )\n",
    "        \n",
    "        # 4. Pooling global (seulement sur les steps valides)\n",
    "        mask_expanded = mask.unsqueeze(-1)\n",
    "        summed = torch.sum(attn_output * (~mask_expanded).float(), dim=1)\n",
    "        context = summed / lengths.float().unsqueeze(-1)\n",
    "        \n",
    "        # 5. Transformation en vecteur latent\n",
    "        z_mean = self.to_mean(context)\n",
    "        z_logvar = self.to_logvar(context)\n",
    "        \n",
    "        return z_mean, z_logvar, attn_weights\n",
    "\n",
    "class SafeAttentionDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim, num_layers, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.latent_to_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Pas d'attention croisée avec l'encodeur pour éviter la fuite!\n",
    "        \n",
    "    def forward(self, z, lengths):\n",
    "        batch_size = z.size(0)\n",
    "        max_length = lengths.max()\n",
    "        \n",
    "        # Initialisation à partir du vecteur latent\n",
    "        h0 = self.latent_to_hidden(z).unsqueeze(0).repeat(self.lstm.num_layers, 1, 1)\n",
    "        c0 = torch.zeros_like(h0)\n",
    "        \n",
    "        # Séquence d'entrée nulle\n",
    "        input_seq = torch.zeros(batch_size, max_length, self.lstm.input_size, device=z.device)\n",
    "        \n",
    "        # LSTM\n",
    "        packed_input = pack_padded_sequence(input_seq, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input, (h0, c0))\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        return self.output_layer(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4b5684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LengthAwareLSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, latent_dim: int, num_layers: int) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder_lstm = nn.LSTM(input_dim, hidden_dim, num_layers, bidirectional=False, batch_first=True)\n",
    "        self.encoder_linear_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.encoder_linear_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        #self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, lengths: torch.Tensor) -> tuple[torch.Tensor]:\n",
    "        packed_input = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (hidden, _) = self.encoder_lstm(packed_input)\n",
    "        #output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        last_hidden = hidden[-1]\n",
    "        mean = self.encoder_linear_mean(last_hidden)\n",
    "        logvar = self.encoder_linear_logvar(last_hidden)\n",
    "        return mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b38617b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "input_dim = 24\n",
    "hidden_dim = 128\n",
    "latent_dim = 24\n",
    "num_layers = 2\n",
    "\n",
    "n_time = 200\n",
    "length_foo = torch.randint(low=50, high=n_time+1, size=(batch_size,))\n",
    "seq_length = max(length_foo).item()\n",
    "x_foo = torch.randn(batch_size, seq_length, input_dim)\n",
    "encoder_foo = LengthAwareLSTMEncoder(input_dim, hidden_dim, latent_dim, num_layers)\n",
    "mean_foo, logvar_foo = encoder_foo(x_foo, length_foo)\n",
    "\n",
    "\n",
    "assert mean_foo.shape == (batch_size, latent_dim)\n",
    "assert logvar_foo.shape == (batch_size, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89a318bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LengthAwareLSTMDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int, hidden_dim: int, output_dim: int, num_layers: int) -> None:\n",
    "        super().__init__()\n",
    "        self.decoder_linear_init = nn.Linear(latent_dim, hidden_dim * num_layers * 2)  # For hidden and cell states of each layer\n",
    "        self.decoder_lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, bidirectional=False, batch_first=True)\n",
    "        self.decoder_output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        #self.dropout = nn.Dropout(p=0.5)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, z: torch.Tensor, lengths: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = z.size(0)\n",
    "\n",
    "        init_states = self.decoder_linear_init(z)\n",
    "        h0 = init_states[:, :self.hidden_dim * self.num_layers].reshape(self.num_layers, batch_size, self.hidden_dim)\n",
    "        c0 = init_states[:, self.hidden_dim * self.num_layers:].reshape(self.num_layers, batch_size, self.hidden_dim)\n",
    "\n",
    "        max_length = torch.max(lengths)\n",
    "        input_seq = torch.zeros(batch_size, max_length, self.hidden_dim, device=z.device)\n",
    "\n",
    "        packed_input = pack_padded_sequence(input_seq, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.decoder_lstm(packed_input, (h0, c0))\n",
    "\n",
    "        transformed_data = self.decoder_output_layer(packed_output.data)\n",
    "        output_packed = torch.nn.utils.rnn.PackedSequence(\n",
    "            data=transformed_data, \n",
    "            batch_sizes=packed_output.batch_sizes,\n",
    "            sorted_indices=packed_output.sorted_indices,\n",
    "            unsorted_indices=packed_output.unsorted_indices\n",
    "        )\n",
    "        output, _ = pad_packed_sequence(output_packed, batch_first=True)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9531e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "seq_length = 200\n",
    "input_dim = 24\n",
    "hidden_dim = 128\n",
    "latent_dim = 24\n",
    "num_layers = 2\n",
    "\n",
    "z_foo = torch.randn(batch_size, latent_dim)\n",
    "decoder_foo = LengthAwareLSTMDecoder(latent_dim, hidden_dim, input_dim, num_layers)\n",
    "masked_output_foo = decoder_foo(z_foo, length_foo)\n",
    "\n",
    "assert masked_output_foo.shape == (batch_size, torch.max(length_foo), input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6eeada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBetaVAE(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, latent_dim: int, lstm_num_layers: int) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = LengthAwareLSTMEncoder(input_dim, hidden_dim, latent_dim, lstm_num_layers)\n",
    "        self.decoder = LengthAwareLSTMDecoder(latent_dim, hidden_dim, input_dim, lstm_num_layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, lengths: torch.Tensor) -> tuple[torch.Tensor]:\n",
    "        z_mean, z_logvar = self.encoder(x, lengths)\n",
    "        z = self.reparameterize(z_mean, z_logvar)\n",
    "        return self.decoder(z, lengths), z_mean, z_logvar\n",
    "\n",
    "    def reparameterize(self, mean: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bc3216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "input_dim = 24\n",
    "hidden_dim = 128\n",
    "latent_dim = 24\n",
    "num_layers = 2\n",
    "\n",
    "n_time = 200\n",
    "length_foo = torch.randint(low=100, high=n_time+1, size=(batch_size,))\n",
    "seq_length = max(length_foo).item()\n",
    "x_foo = torch.randn(batch_size, seq_length, input_dim)\n",
    "vae_foo = LSTMBetaVAE(input_dim, hidden_dim, latent_dim, num_layers)\n",
    "output_foo, mean_foo, logvar_foo = vae_foo(x_foo, length_foo)\n",
    "\n",
    "\n",
    "assert mean_foo.shape == (batch_size, latent_dim)\n",
    "assert logvar_foo.shape == (batch_size, latent_dim)\n",
    "assert output_foo.shape == (batch_size, torch.max(length_foo), input_dim)\n",
    "assert output_foo.shape == x_foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7975cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_function(\n",
    "    x_recon: torch.Tensor, \n",
    "    x: torch.Tensor, \n",
    "    z_mean: torch.Tensor, \n",
    "    z_logvar: torch.Tensor, \n",
    "    lengths: torch.Tensor, \n",
    "    beta: float = 1.0\n",
    "    ) -> tuple[torch.Tensor]:\n",
    "\n",
    "    batch_size, seq_length, _ = x.shape\n",
    "\n",
    "    mask = torch.arange(seq_length, device=x_recon.device)[None, :] < lengths[:, None]      # shape [batch_size, max_length]\n",
    "    mask = mask.unsqueeze(-1).float()                                                       # shape [batch_size, max_length, 1]\n",
    "\n",
    "    MSE = nn.functional.mse_loss(x_recon, x, reduction='none')\n",
    "    MSE = (MSE * mask).sum(dim=(1,2))        # Mask application\n",
    "    num_valid_steps = mask.sum(dim=(1,2))    # Normalizing factor\n",
    "    MSE = torch.where(num_valid_steps > 0, MSE / num_valid_steps, torch.zeros_like(MSE))\n",
    "\n",
    "    KLD = -0.5 * torch.sum(1 + z_logvar - z_mean.pow(2) - z_logvar.exp(), dim=1)\n",
    "    KLD = KLD / batch_size\n",
    "\n",
    "    TOTAL = torch.mean(MSE + beta * KLD)\n",
    "    MSE = torch.mean(MSE)\n",
    "    KLD = torch.mean(KLD)\n",
    "\n",
    "    return TOTAL, MSE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a16018d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(91.8865)\n",
      "tensor(48.0560)\n",
      "tensor(2.1915)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "input_dim = 24\n",
    "hidden_dim = 128\n",
    "latent_dim = 24\n",
    "num_layers = 2\n",
    "\n",
    "n_time = 200\n",
    "length_foo = torch.randint(low=100, high=n_time+1, size=(batch_size,))\n",
    "seq_length = max(length_foo).item()\n",
    "x_foo = torch.randn(batch_size, seq_length, input_dim)\n",
    "x_recon_foo = torch.randn(batch_size, seq_length, input_dim)\n",
    "\n",
    "z_mean_foo = torch.randn(batch_size, latent_dim)\n",
    "z_logvar_foo = torch.randn(batch_size, latent_dim)\n",
    "\n",
    "beta = 20.0\n",
    "\n",
    "loss, loss_mse, loss_kld = vae_loss_function(\n",
    "    x_foo, x_recon_foo, z_mean_foo, z_logvar_foo, length_foo, beta\n",
    ")\n",
    "\n",
    "print(loss)\n",
    "print(loss_mse)\n",
    "print(loss_kld)\n",
    "assert loss.shape == torch.Size([])\n",
    "assert loss_mse.shape == torch.Size([])\n",
    "assert loss_kld.shape == torch.Size([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47b28c",
   "metadata": {},
   "source": [
    "## 3. Train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd62f44f",
   "metadata": {},
   "source": [
    "- On choisit d'éliminer les outliers par rapport à la densité de la reconstruction et non à la clusterisation de l'espace latent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc740d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "803a03e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from magnetics_diagnostic_analysis.ml_tools.train_callbacks import EarlyStopping, LRScheduling, GradientClipping, DropOutScheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d85d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_reconstruction_error(\n",
    "    x_recon: torch.Tensor, \n",
    "    x: torch.Tensor, \n",
    "    lengths: torch.Tensor, \n",
    "    ) -> tuple[torch.Tensor]:\n",
    "\n",
    "    _, seq_length, _ = x.shape\n",
    "\n",
    "    mask = torch.arange(seq_length, device=x_recon.device)[None, :] < lengths[:, None]      # shape [batch_size, max_length]\n",
    "    mask = mask.unsqueeze(-1).float()                                                       # shape [batch_size, max_length, 1]\n",
    "\n",
    "    mse = nn.functional.mse_loss(x_recon, x, reduction='none')\n",
    "    mse = (mse * mask).sum(dim=(1,2))        # Mask application\n",
    "    num_valid_steps = mask.sum(dim=(1,2))    # Normalizing factor\n",
    "    mse = torch.where(num_valid_steps > 0, mse / num_valid_steps, torch.zeros_like(mse))\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "217a63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iterative_vae_pipeline(\n",
    "    train_dataset: Dataset,\n",
    "    n_iterations: int = 5,\n",
    "    n_epochs_per_iter: int = 50,\n",
    "    batch_size: int = 32,\n",
    "    reconstruction_percentile_threshold: float = 95,\n",
    "    kde_bandwidth: float = 0.5,\n",
    "    dbscan_eps: float = 0.5,\n",
    "    dbscan_min_samples: int = 5,\n",
    "    device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ") -> dict:\n",
    "    \n",
    "    # Model parameters\n",
    "    sample_data, _ = train_dataset[0]\n",
    "    input_dim = sample_data.shape[-1]\n",
    "    hidden_dim = 256\n",
    "    latent_dim = 128\n",
    "    lstm_layers = 2\n",
    "\n",
    "    # Good and bad health indices initialization\n",
    "    valid_indices = list(range(len(train_dataset)))\n",
    "    all_anomaly_indices = np.array([], dtype=int)\n",
    "\n",
    "    # Model storage\n",
    "    vae_models = []\n",
    "\n",
    "    full_loader = DataLoader(\n",
    "            dataset=train_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True, \n",
    "            collate_fn=pad_sequences_smartly, \n",
    "            drop_last=False)\n",
    "\n",
    "    for iteration in range(n_iterations):\n",
    "        print(f\"Iteration {iteration + 1}/{n_iterations}\")\n",
    "        print(f\"Training on {len(valid_indices)} samples...\")\n",
    "\n",
    "        # Data SubSet creation\n",
    "        current_subset = Subset(train_dataset, valid_indices)\n",
    "        train_loader = DataLoader(\n",
    "            dataset=current_subset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True, \n",
    "            collate_fn=pad_sequences_smartly, \n",
    "            drop_last=False)\n",
    "\n",
    "        # VAE Training\n",
    "        vae = LSTMBetaVAE(input_dim, hidden_dim, latent_dim, lstm_layers).to(device)\n",
    "        optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "        # Training loop\n",
    "        vae.train()\n",
    "        print(f\"{'Epoch':<40} {'Loss':<20} {'mse':<20} {'kld':<20}\")\n",
    "        for epoch in range(n_epochs_per_iter):\n",
    "            total_loss = 0\n",
    "            for batch_data, batch_lengths in tqdm(train_loader, desc=f\"Training VAE number {iteration + 1}\", leave=False):\n",
    "                batch_data = batch_data.to(device)\n",
    "                batch_lengths = batch_lengths.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                recon_batch, z_mean, z_logvar = vae(batch_data, batch_lengths)\n",
    "                loss, mse, kld = vae_loss_function(recon_batch, batch_data, z_mean, z_logvar, batch_lengths, beta=3.0)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                total_mse, total_kld = mse.item(), kld.item()\n",
    "\n",
    "            epo, total_loss, total_mse, total_kld = (epoch+1)/n_epochs_per_iter, total_loss/len(train_loader), total_mse/len(train_loader), total_kld/len(train_loader)\n",
    "            print(f\"{epo:<40} {total_loss:<20} {total_mse:<20} {total_kld:<20}\")\n",
    "\n",
    "        # VAE Evaluation\n",
    "        vae.eval()\n",
    "        reconstruction_errors = torch.zeros(len(train_dataset))           # or len(current_subset)\n",
    "        with torch.no_grad():\n",
    "            i = 0\n",
    "            for batch_data, batch_lengths in tqdm(full_loader, desc=f\"Evaluating VAE number {iteration + 1}\", leave=False):\n",
    "                batch_data = batch_data.to(device)\n",
    "                batch_lengths = batch_lengths.to(device)\n",
    "                \n",
    "                recon_batch, _, _ = vae(batch_data, batch_lengths)\n",
    "                mse = vae_reconstruction_error(recon_batch, batch_data, batch_lengths)\n",
    "                reconstruction_errors[i*batch_size : (i+1)*batch_size] = mse\n",
    "                i += 1\n",
    "\n",
    "        reconstruction_errors = reconstruction_errors.cpu().numpy()\n",
    "        # Outlier detection with KDE\n",
    "        kde = KernelDensity(bandwidth=kde_bandwidth)\n",
    "        kde.fit(reconstruction_errors.reshape(-1, 1))  # shape [n_samples, 1]\n",
    "        density_scores = np.exp(kde.score_samples(reconstruction_errors.reshape(-1, 1)))       # shape [n_samples]\n",
    "\n",
    "        threshold = np.percentile(density_scores, 100 - reconstruction_percentile_threshold)\n",
    "        new_anomalies = np.where(density_scores < threshold)[0]\n",
    "\n",
    "        # Update anomaly indices\n",
    "        all_anomaly_indices = np.unique(np.concatenate([all_anomaly_indices, new_anomalies]))\n",
    "        valid_indices = list(np.setdiff1d(np.arange(len(train_dataset)), all_anomaly_indices))\n",
    "        \n",
    "        vae_models.append(vae.state_dict())\n",
    "        print(f\"New anomalies detected: {len(new_anomalies)}\")\n",
    "        print(f\"Total anomalies: {len(all_anomaly_indices)}\\n\")\n",
    "\n",
    "        # Delete cache and big variables\n",
    "        del vae, optimizer, reconstruction_errors, kde\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "    # Last training phase\n",
    "    print(\"Training final model...\")\n",
    "    final_subset = Subset(train_dataset, valid_indices)\n",
    "    final_loader = DataLoader(final_subset, batch_size=batch_size, shuffle=True, collate_fn=pad_sequences_smartly, drop_last=False)\n",
    "\n",
    "    final_vae = LSTMBetaVAE(input_dim, hidden_dim, latent_dim, lstm_layers).to(device)\n",
    "    optimizer = torch.optim.Adam(final_vae.parameters(), lr=1e-3)\n",
    "    \n",
    "    final_vae.train()\n",
    "    print(f\"{'Epoch':<40} {'Loss':<20} {'mse':<20} {'kld':<20}\")\n",
    "    for epoch in range(n_epochs_per_iter):\n",
    "        total_loss = 0\n",
    "        for batch_data, batch_lengths in tqdm(final_loader, desc=\"Training final VAE\", leave=False):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_lengths = batch_lengths.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, z_mean, z_logvar = final_vae(batch_data, batch_lengths)\n",
    "            loss, mse, kld = vae_loss_function(recon_batch, batch_data, z_mean, z_logvar, batch_lengths)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_mse, total_kld = mse.item(), kld.item()\n",
    "\n",
    "        epo, total_loss, total_mse, total_kld = (epoch+1)/n_epochs_per_iter, total_loss/len(train_loader), total_mse/len(train_loader), total_kld/len(train_loader)\n",
    "        print(f\"{epo:<40} {total_loss:<20} {total_mse:<20} {total_kld:<20}\")\n",
    "\n",
    "    # Latent features for all data\n",
    "    final_vae.eval()\n",
    "    with torch.no_grad():\n",
    "        z_mean_all = []\n",
    "        for batch_data, batch_lengths in tqdm(full_loader, desc=\"Extracting latent features\", leave=False):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_lengths = batch_lengths.to(device)\n",
    "\n",
    "            z_mean, _ = final_vae.encoder(batch_data, batch_lengths)\n",
    "            z_mean_all.append(z_mean.cpu().numpy())\n",
    "        \n",
    "        latent_features = np.concatenate(z_mean_all, axis=0)\n",
    "\n",
    "    # Final clustering on latent space on all train_dataset, with DBScan\n",
    "    dbscan = DBSCAN(eps=dbscan_eps, min_samples=dbscan_min_samples)\n",
    "    clusters = dbscan.fit_predict(latent_features)\n",
    "    outlier_mask = clusters == -1\n",
    "    \n",
    "    return {\n",
    "        'final_vae': final_vae,\n",
    "        'latent_features': latent_features,\n",
    "        'anomaly_indices': all_anomaly_indices,\n",
    "        'clusters': clusters,\n",
    "        'outlier_mask': outlier_mask,\n",
    "        'vae_models': vae_models\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a017003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/2\n",
      "Training on 3682 samples...\n",
      "Epoch                                    Loss                 mse                  kld                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5                                      259997949846.5964    77275950.30526887    0.07982567948274545 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0                                      259388006326.85715   74225366.97881585    2.474522380839218   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New anomalies detected: 0\n",
      "Total anomalies: 0\n",
      "\n",
      "Iteration 2/2\n",
      "Training on 3682 samples...\n",
      "Epoch                                    Loss                 mse                  kld                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5                                      259998333782.9093    82269243.51548071    0.0049988540989235  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0                                      259383494653.2189    80830245.96197718    0.6236869318856939  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New anomalies detected: 0\n",
      "Total anomalies: 0\n",
      "\n",
      "Training final model...\n",
      "Epoch                                    Loss                 mse                  kld                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.58 GiB of which 163.12 MiB is free. Process 747003 has 135.45 MiB memory in use. Process 2951200 has 135.51 MiB memory in use. Process 3952432 has 135.51 MiB memory in use. Process 2130804 has 170.70 MiB memory in use. Including non-PyTorch memory, this process has 226.00 MiB memory in use. Of the allocated memory 74.15 MiB is allocated by PyTorch, and 13.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m dbscan_min_samples = \u001b[32m5\u001b[39m\n\u001b[32m      8\u001b[39m device  = config.DEVICE\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m results = \u001b[43mtrain_iterative_vae_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_epochs_per_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_epochs_per_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreconstruction_percentile_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreconstruction_percentile_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkde_bandwidth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkde_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdbscan_eps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdbscan_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdbscan_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdbscan_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 126\u001b[39m, in \u001b[36mtrain_iterative_vae_pipeline\u001b[39m\u001b[34m(train_dataset, n_iterations, n_epochs_per_iter, batch_size, reconstruction_percentile_threshold, kde_bandwidth, dbscan_eps, dbscan_min_samples, device)\u001b[39m\n\u001b[32m    123\u001b[39m batch_lengths = batch_lengths.to(device)\n\u001b[32m    125\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m recon_batch, z_mean, z_logvar = \u001b[43mfinal_vae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m loss, mse, kld = vae_loss_function(recon_batch, batch_data, z_mean, z_logvar, batch_lengths)\n\u001b[32m    128\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mLSTMBetaVAE.forward\u001b[39m\u001b[34m(self, x, lengths)\u001b[39m\n\u001b[32m      8\u001b[39m z_mean, z_logvar = \u001b[38;5;28mself\u001b[39m.encoder(x, lengths)\n\u001b[32m      9\u001b[39m z = \u001b[38;5;28mself\u001b[39m.reparameterize(z_mean, z_logvar)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m, z_mean, z_logvar\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mLengthAwareLSTMDecoder.forward\u001b[39m\u001b[34m(self, z, lengths)\u001b[39m\n\u001b[32m     19\u001b[39m input_seq = torch.zeros(batch_size, max_length, \u001b[38;5;28mself\u001b[39m.hidden_dim, device=z.device)\n\u001b[32m     21\u001b[39m packed_input = pack_padded_sequence(input_seq, lengths.cpu(), batch_first=\u001b[38;5;28;01mTrue\u001b[39;00m, enforce_sorted=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m packed_output, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m transformed_data = \u001b[38;5;28mself\u001b[39m.decoder_output_layer(packed_output.data)\n\u001b[32m     25\u001b[39m output_packed = torch.nn.utils.rnn.PackedSequence(\n\u001b[32m     26\u001b[39m     data=transformed_data, \n\u001b[32m     27\u001b[39m     batch_sizes=packed_output.batch_sizes,\n\u001b[32m     28\u001b[39m     sorted_indices=packed_output.sorted_indices,\n\u001b[32m     29\u001b[39m     unsorted_indices=packed_output.unsorted_indices\n\u001b[32m     30\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:920\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m    917\u001b[39m     result = _VF.lstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m._flat_weights, \u001b[38;5;28mself\u001b[39m.bias, \u001b[38;5;28mself\u001b[39m.num_layers,\n\u001b[32m    918\u001b[39m                       \u001b[38;5;28mself\u001b[39m.dropout, \u001b[38;5;28mself\u001b[39m.training, \u001b[38;5;28mself\u001b[39m.bidirectional, \u001b[38;5;28mself\u001b[39m.batch_first)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    922\u001b[39m output = result[\u001b[32m0\u001b[39m]\n\u001b[32m    923\u001b[39m hidden = result[\u001b[32m1\u001b[39m:]\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.58 GiB of which 163.12 MiB is free. Process 747003 has 135.45 MiB memory in use. Process 2951200 has 135.51 MiB memory in use. Process 3952432 has 135.51 MiB memory in use. Process 2130804 has 170.70 MiB memory in use. Including non-PyTorch memory, this process has 226.00 MiB memory in use. Of the allocated memory 74.15 MiB is allocated by PyTorch, and 13.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "n_iterations = 2\n",
    "n_epochs_per_iter = 2\n",
    "batch_size = 1\n",
    "reconstruction_percentile_threshold = 50\n",
    "kde_bandwidth = 0.5\n",
    "dbscan_eps = 0.5\n",
    "dbscan_min_samples = 5\n",
    "device  = config.DEVICE\n",
    "\n",
    "results = train_iterative_vae_pipeline(\n",
    "    train_dataset=train_set,\n",
    "    n_iterations=n_iterations,\n",
    "    n_epochs_per_iter=n_epochs_per_iter,\n",
    "    batch_size=batch_size,\n",
    "    reconstruction_percentile_threshold=reconstruction_percentile_threshold,\n",
    "    kde_bandwidth=kde_bandwidth,\n",
    "    dbscan_eps=dbscan_eps,\n",
    "    dbscan_min_samples=dbscan_min_samples,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9fb6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64267c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d087274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(test_dataset, trained_vae, device):\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_dataset, \n",
    "        batch_size=32, \n",
    "        shuffle=False, \n",
    "        collate_fn=pad_sequences_smartly, \n",
    "        drop_last=False\n",
    "    )\n",
    "    trained_vae.eval()\n",
    "    \n",
    "    reconstruction_errors = []\n",
    "    latent_features = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_lengths in test_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_lengths = batch_lengths.to(device)\n",
    "            \n",
    "            recon_batch, z_mean, _ = trained_vae(batch_data, batch_lengths)\n",
    "            # Store latent features\n",
    "            latent_features.append(z_mean.cpu().numpy())\n",
    "\n",
    "            mse = vae_reconstruction_error(recon_batch, batch_data, batch_lengths)\n",
    "            # Store reconstruction errors\n",
    "            reconstruction_errors.extend(mse.cpu().numpy())\n",
    "    \n",
    "    return np.array(reconstruction_errors), np.concatenate(latent_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca924ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda6cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_time(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    n_epochs: int,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device\n",
    "):\n",
    "    current_data = data.copy()\n",
    "    anomaly_indices = np.array([], dtype=int)\n",
    "\n",
    "    reconstruction_error_threshold_percentile = 95\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            data, lengths = batch\n",
    "            data = data.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data, lengths)\n",
    "            loss = criterion(output, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8173b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_iterations: int):\n",
    "    for i in range(n_iterations):\n",
    "        model = VAE()\n",
    "        train_one_time(model, train_loader, n_epochs, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868180fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5b839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b925fc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c850977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITER-magnetics-diagnostic-analysis (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

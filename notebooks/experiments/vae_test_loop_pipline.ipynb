{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1e52f5",
   "metadata": {},
   "source": [
    "# Test of looping over $\\beta$-VAE to detect and classify outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656a3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d22e804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Choosen device = cuda:0\n"
     ]
    }
   ],
   "source": [
    "from magnetics_diagnostic_analysis.project_vae.setting_vae import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c251617f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Torch version?  2.4.1+cu121\n",
      "Cuda?           True\n",
      "\n",
      "GPU number : 2\n",
      "GPU 0: Tesla T4\n",
      "GPU 1: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from magnetics_diagnostic_analysis.ml_tools.pytorch_device_selection import print_torch_info\n",
    "print_torch_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cd8107",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"vae\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9ccbb4",
   "metadata": {},
   "source": [
    "### 1. Create dataset and DataLoader\n",
    "\n",
    "I took the decision that one data sample will be : all the time values of one shot and for all diagnostics. It will be easy after, to reduce to one diagnostic only (It wouldn't habe been the case if we wanted to use all diagnostics for one timestep -> there reduce to one diagnostic just give us one number and that is to small).\n",
    "\n",
    "As all shots own different lenghts, we are going to use LSTM unit in entry of our VAE. This LSTM unit is combined with padded sequence and have masking behaviour.\n",
    "\n",
    "Thus, after the LSTM, we will have a constant size tensor (the LSTM hidden state) that we can use in our VAE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e6fffd",
   "metadata": {},
   "source": [
    "Consideration:\n",
    "\n",
    "We want our model to be robust to any different size during testing time.\n",
    "\n",
    "Thus, we are going to find the max_lenght for each batch size in the dataloader.\n",
    "\n",
    "And thanks to the two functions `pack_padded_sequence`, `pad_packed_sequence`, the LSTM is aware of the true lenght of each sequence and use masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9f65087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc0f8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base rgba(0, 0, 0, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, white)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 15))\n",
       "  );\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, #111111)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 15))\n",
       "  );\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "  border: 2px solid transparent !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0) !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  border-color: var(--xr-background-color-row-odd);\n",
       "  margin-bottom: 0;\n",
       "  padding-top: 2px;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "  border-color: var(--xr-background-color-row-even);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  border-top: 2px dotted var(--xr-background-color);\n",
       "  padding-bottom: 20px !important;\n",
       "  padding-top: 10px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in + label,\n",
       ".xr-var-data-in + label,\n",
       ".xr-index-data-in + label {\n",
       "  padding: 0 1px;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-data > pre,\n",
       ".xr-index-data > pre,\n",
       ".xr-var-data > table > tbody > tr {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked + label > .xr-icon-file-text2,\n",
       ".xr-var-data-in:checked + label > .xr-icon-database,\n",
       ".xr-index-data-in:checked + label > .xr-icon-database {\n",
       "  color: var(--xr-font-color0);\n",
       "  filter: drop-shadow(1px 1px 5px var(--xr-font-color2));\n",
       "  stroke-width: 0.8px;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 10GB\n",
       "Dimensions:                                   (time: 12877819,\n",
       "                                               b_field_tor_probe_saddle_voltage_channel: 9,\n",
       "                                               b_field_pol_probe_obr_channel: 18,\n",
       "                                               b_field_pol_probe_ccbv_channel: 37,\n",
       "                                               flux_loop_channel: 14,\n",
       "                                               b_field_pol_probe_obv_channel: 17)\n",
       "Coordinates:\n",
       "  * b_field_tor_probe_saddle_voltage_channel  (b_field_tor_probe_saddle_voltage_channel) &lt;U15 540B ...\n",
       "  * time                                      (time) float64 103MB -0.0692 .....\n",
       "  * b_field_pol_probe_obr_channel             (b_field_pol_probe_obr_channel) &lt;U9 648B ...\n",
       "  * b_field_pol_probe_ccbv_channel            (b_field_pol_probe_ccbv_channel) &lt;U10 1kB ...\n",
       "  * flux_loop_channel                         (flux_loop_channel) &lt;U12 672B &#x27;...\n",
       "  * b_field_pol_probe_obv_channel             (b_field_pol_probe_obv_channel) &lt;U9 612B ...\n",
       "Data variables:\n",
       "    b_field_tor_probe_saddle_voltage          (time, b_field_tor_probe_saddle_voltage_channel) float64 927MB ...\n",
       "    b_field_pol_probe_obr_field               (time, b_field_pol_probe_obr_channel) float64 2GB ...\n",
       "    ip                                        (time) float64 103MB ...\n",
       "    b_field_pol_probe_ccbv_field              (time, b_field_pol_probe_ccbv_channel) float64 4GB ...\n",
       "    flux_loop_flux                            (time, flux_loop_channel) float64 1GB ...\n",
       "    b_field_pol_probe_obv_field               (time, b_field_pol_probe_obv_channel) float64 2GB ...\n",
       "    shot_index                                (time) int64 103MB ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-36f2f013-f074-4e5d-8542-4fe1c575c991' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-36f2f013-f074-4e5d-8542-4fe1c575c991' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 12877819</li><li><span class='xr-has-index'>b_field_tor_probe_saddle_voltage_channel</span>: 9</li><li><span class='xr-has-index'>b_field_pol_probe_obr_channel</span>: 18</li><li><span class='xr-has-index'>b_field_pol_probe_ccbv_channel</span>: 37</li><li><span class='xr-has-index'>flux_loop_channel</span>: 14</li><li><span class='xr-has-index'>b_field_pol_probe_obv_channel</span>: 17</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-8199f69b-7a51-43ad-8bd6-de6d1e37a09e' class='xr-section-summary-in' type='checkbox'  checked><label for='section-8199f69b-7a51-43ad-8bd6-de6d1e37a09e' class='xr-section-summary' >Coordinates: <span>(6)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>b_field_tor_probe_saddle_voltage_channel</span></div><div class='xr-var-dims'>(b_field_tor_probe_saddle_voltage_channel)</div><div class='xr-var-dtype'>&lt;U15</div><div class='xr-var-preview xr-preview'>&#x27;XMB_SAD/OUT/M01&#x27; ... &#x27;XMB_SAD/O...</div><input id='attrs-2f4666ef-507a-41a3-8cc0-2d2c29543091' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-2f4666ef-507a-41a3-8cc0-2d2c29543091' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c6b51cdc-d84a-4427-9864-6578f3a23f60' class='xr-var-data-in' type='checkbox'><label for='data-c6b51cdc-d84a-4427-9864-6578f3a23f60' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;XMB_SAD/OUT/M01&#x27;, &#x27;XMB_SAD/OUT/M02&#x27;, &#x27;XMB_SAD/OUT/M03&#x27;,\n",
       "       &#x27;XMB_SAD/OUT/M04&#x27;, &#x27;XMB_SAD/OUT/M05&#x27;, &#x27;XMB_SAD/OUT/M06&#x27;,\n",
       "       &#x27;XMB_SAD/OUT/M07&#x27;, &#x27;XMB_SAD/OUT/M08&#x27;, &#x27;XMB_SAD/OUT/M09&#x27;], dtype=&#x27;&lt;U15&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-0.0692 -0.06895 ... 0.3918 0.3921</div><input id='attrs-bc24c045-bad0-4afb-ae28-a65d40217065' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-bc24c045-bad0-4afb-ae28-a65d40217065' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-33bd54b1-5dfe-48a7-9647-68e7602f7007' class='xr-var-data-in' type='checkbox'><label for='data-33bd54b1-5dfe-48a7-9647-68e7602f7007' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>s</dd></dl></div><div class='xr-var-data'><pre>array([-0.0692 , -0.06895, -0.0687 , ...,  0.3916 ,  0.39185,  0.3921 ])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>b_field_pol_probe_obr_channel</span></div><div class='xr-var-dims'>(b_field_pol_probe_obr_channel)</div><div class='xr-var-dtype'>&lt;U9</div><div class='xr-var-preview xr-preview'>&#x27;AMB_OBR01&#x27; ... &#x27;AMB_OBR18&#x27;</div><input id='attrs-a490249e-4d6e-4b30-884a-9b5f99117a47' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-a490249e-4d6e-4b30-884a-9b5f99117a47' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9aed0283-4fcd-458b-9ff6-357a9b71bbc5' class='xr-var-data-in' type='checkbox'><label for='data-9aed0283-4fcd-458b-9ff6-357a9b71bbc5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;AMB_OBR01&#x27;, &#x27;AMB_OBR02&#x27;, &#x27;AMB_OBR03&#x27;, &#x27;AMB_OBR04&#x27;, &#x27;AMB_OBR05&#x27;,\n",
       "       &#x27;AMB_OBR06&#x27;, &#x27;AMB_OBR07&#x27;, &#x27;AMB_OBR08&#x27;, &#x27;AMB_OBR09&#x27;, &#x27;AMB_OBR10&#x27;,\n",
       "       &#x27;AMB_OBR11&#x27;, &#x27;AMB_OBR12&#x27;, &#x27;AMB_OBR13&#x27;, &#x27;AMB_OBR14&#x27;, &#x27;AMB_OBR15&#x27;,\n",
       "       &#x27;AMB_OBR16&#x27;, &#x27;AMB_OBR17&#x27;, &#x27;AMB_OBR18&#x27;], dtype=&#x27;&lt;U9&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>b_field_pol_probe_ccbv_channel</span></div><div class='xr-var-dims'>(b_field_pol_probe_ccbv_channel)</div><div class='xr-var-dtype'>&lt;U10</div><div class='xr-var-preview xr-preview'>&#x27;AMB_CCBV01&#x27; ... &#x27;AMB_CCBV40&#x27;</div><input id='attrs-8049e775-3d59-437d-b160-066ef63ee00d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-8049e775-3d59-437d-b160-066ef63ee00d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-179a22f8-2da9-497d-be6a-c171069568f1' class='xr-var-data-in' type='checkbox'><label for='data-179a22f8-2da9-497d-be6a-c171069568f1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;AMB_CCBV01&#x27;, &#x27;AMB_CCBV02&#x27;, &#x27;AMB_CCBV03&#x27;, &#x27;AMB_CCBV04&#x27;, &#x27;AMB_CCBV05&#x27;,\n",
       "       &#x27;AMB_CCBV06&#x27;, &#x27;AMB_CCBV07&#x27;, &#x27;AMB_CCBV08&#x27;, &#x27;AMB_CCBV09&#x27;, &#x27;AMB_CCBV11&#x27;,\n",
       "       &#x27;AMB_CCBV12&#x27;, &#x27;AMB_CCBV14&#x27;, &#x27;AMB_CCBV15&#x27;, &#x27;AMB_CCBV16&#x27;, &#x27;AMB_CCBV17&#x27;,\n",
       "       &#x27;AMB_CCBV18&#x27;, &#x27;AMB_CCBV19&#x27;, &#x27;AMB_CCBV20&#x27;, &#x27;AMB_CCBV21&#x27;, &#x27;AMB_CCBV23&#x27;,\n",
       "       &#x27;AMB_CCBV24&#x27;, &#x27;AMB_CCBV25&#x27;, &#x27;AMB_CCBV26&#x27;, &#x27;AMB_CCBV27&#x27;, &#x27;AMB_CCBV28&#x27;,\n",
       "       &#x27;AMB_CCBV29&#x27;, &#x27;AMB_CCBV30&#x27;, &#x27;AMB_CCBV31&#x27;, &#x27;AMB_CCBV32&#x27;, &#x27;AMB_CCBV33&#x27;,\n",
       "       &#x27;AMB_CCBV34&#x27;, &#x27;AMB_CCBV35&#x27;, &#x27;AMB_CCBV36&#x27;, &#x27;AMB_CCBV37&#x27;, &#x27;AMB_CCBV38&#x27;,\n",
       "       &#x27;AMB_CCBV39&#x27;, &#x27;AMB_CCBV40&#x27;], dtype=&#x27;&lt;U10&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>flux_loop_channel</span></div><div class='xr-var-dims'>(flux_loop_channel)</div><div class='xr-var-dtype'>&lt;U12</div><div class='xr-var-preview xr-preview'>&#x27;AMB_FL/CC03&#x27; ... &#x27;AMB_FL/P5U/1&#x27;</div><input id='attrs-7bb19333-099f-4368-8665-93ccb6622a86' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-7bb19333-099f-4368-8665-93ccb6622a86' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d008c5e7-0612-4103-b0b9-bcb9bb2e3f94' class='xr-var-data-in' type='checkbox'><label for='data-d008c5e7-0612-4103-b0b9-bcb9bb2e3f94' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;AMB_FL/CC03&#x27;, &#x27;AMB_FL/CC04&#x27;, &#x27;AMB_FL/CC05&#x27;, &#x27;AMB_FL/CC07&#x27;,\n",
       "       &#x27;AMB_FL/CC09&#x27;, &#x27;AMB_FL/P3L/4&#x27;, &#x27;AMB_FL/P3U/1&#x27;, &#x27;AMB_FL/P3U/4&#x27;,\n",
       "       &#x27;AMB_FL/P4L/1&#x27;, &#x27;AMB_FL/P4L/4&#x27;, &#x27;AMB_FL/P4U/4&#x27;, &#x27;AMB_FL/P5L/1&#x27;,\n",
       "       &#x27;AMB_FL/P5L/4&#x27;, &#x27;AMB_FL/P5U/1&#x27;], dtype=&#x27;&lt;U12&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>b_field_pol_probe_obv_channel</span></div><div class='xr-var-dims'>(b_field_pol_probe_obv_channel)</div><div class='xr-var-dtype'>&lt;U9</div><div class='xr-var-preview xr-preview'>&#x27;AMB_OBV01&#x27; ... &#x27;AMB_OBV18&#x27;</div><input id='attrs-889d98ee-e75b-4688-962e-6d3440667320' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-889d98ee-e75b-4688-962e-6d3440667320' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-0319162d-5e87-41b2-9998-9995e43fd3dc' class='xr-var-data-in' type='checkbox'><label for='data-0319162d-5e87-41b2-9998-9995e43fd3dc' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;AMB_OBV01&#x27;, &#x27;AMB_OBV02&#x27;, &#x27;AMB_OBV03&#x27;, &#x27;AMB_OBV04&#x27;, &#x27;AMB_OBV05&#x27;,\n",
       "       &#x27;AMB_OBV06&#x27;, &#x27;AMB_OBV07&#x27;, &#x27;AMB_OBV08&#x27;, &#x27;AMB_OBV09&#x27;, &#x27;AMB_OBV11&#x27;,\n",
       "       &#x27;AMB_OBV12&#x27;, &#x27;AMB_OBV13&#x27;, &#x27;AMB_OBV14&#x27;, &#x27;AMB_OBV15&#x27;, &#x27;AMB_OBV16&#x27;,\n",
       "       &#x27;AMB_OBV17&#x27;, &#x27;AMB_OBV18&#x27;], dtype=&#x27;&lt;U9&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-fc85168a-b1f2-407f-ba6a-f38e563da624' class='xr-section-summary-in' type='checkbox'  checked><label for='section-fc85168a-b1f2-407f-ba6a-f38e563da624' class='xr-section-summary' >Data variables: <span>(7)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>b_field_tor_probe_saddle_voltage</span></div><div class='xr-var-dims'>(time, b_field_tor_probe_saddle_voltage_channel)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-bdf7e034-69ed-4a09-b9de-426a6b04b8a5' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-bdf7e034-69ed-4a09-b9de-426a6b04b8a5' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-3d06f1fd-6978-44b3-88e4-747208cda562' class='xr-var-data-in' type='checkbox'><label for='data-3d06f1fd-6978-44b3-88e4-747208cda562' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd></dd><dt><span>imas :</span></dt><dd>magnetics.b_field_tor_probe[:].voltage.data</dd><dt><span>name :</span></dt><dd>b_field_tor_probe_saddle_voltage</dd><dt><span>uda_name :</span></dt><dd>XMB_SAD/OUT/M01</dd><dt><span>units :</span></dt><dd>V</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[115900371 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>b_field_pol_probe_obr_field</span></div><div class='xr-var-dims'>(time, b_field_pol_probe_obr_channel)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-32e98afb-2017-447a-9a29-ef12a748ae8b' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-32e98afb-2017-447a-9a29-ef12a748ae8b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-993a3131-f4e0-48cf-ad7a-c45834cc7a41' class='xr-var-data-in' type='checkbox'><label for='data-993a3131-f4e0-48cf-ad7a-c45834cc7a41' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd>Outer Br array</dd><dt><span>imas :</span></dt><dd>magnetics.b_field_pol_probe[:].field.data</dd><dt><span>label :</span></dt><dd>OBR01</dd><dt><span>name :</span></dt><dd>b_field_pol_probe_obr_field</dd><dt><span>uda_name :</span></dt><dd>AMB_OBR01</dd><dt><span>units :</span></dt><dd>T</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[231800742 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>ip</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-559c141d-ae3b-4764-b689-995c4ff774ba' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-559c141d-ae3b-4764-b689-995c4ff774ba' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-edd71a31-8116-41e5-b6f2-18c695d0f59b' class='xr-var-data-in' type='checkbox'><label for='data-edd71a31-8116-41e5-b6f2-18c695d0f59b' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd></dd><dt><span>imas :</span></dt><dd>magnetics.ip[:].data</dd><dt><span>label :</span></dt><dd>Plasma Current</dd><dt><span>name :</span></dt><dd>ip</dd><dt><span>uda_name :</span></dt><dd>AMC_PLASMA CURRENT</dd><dt><span>units :</span></dt><dd>A</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[12877819 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>b_field_pol_probe_ccbv_field</span></div><div class='xr-var-dims'>(time, b_field_pol_probe_ccbv_channel)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-98a69d2b-055a-49b6-a355-cf3acb93fef8' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-98a69d2b-055a-49b6-a355-cf3acb93fef8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c44af4f7-f1b0-46f6-b9d0-11b810e94fd7' class='xr-var-data-in' type='checkbox'><label for='data-c44af4f7-f1b0-46f6-b9d0-11b810e94fd7' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd>Centre column Bv array</dd><dt><span>imas :</span></dt><dd>magnetics.b_field_pol_probe[:].field.data</dd><dt><span>label :</span></dt><dd>CCBV01</dd><dt><span>name :</span></dt><dd>b_field_pol_probe_ccbv_field</dd><dt><span>uda_name :</span></dt><dd>AMB_CCBV01</dd><dt><span>units :</span></dt><dd>T</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[476479303 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>flux_loop_flux</span></div><div class='xr-var-dims'>(time, flux_loop_channel)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-95123e12-5cbc-4447-ac88-4194243eff80' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-95123e12-5cbc-4447-ac88-4194243eff80' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d0e610d1-c54d-436d-aea3-bd8a7fecb413' class='xr-var-data-in' type='checkbox'><label for='data-d0e610d1-c54d-436d-aea3-bd8a7fecb413' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd></dd><dt><span>imas :</span></dt><dd>magnetics.flux_loop[:].flux.data</dd><dt><span>label :</span></dt><dd>FL/CC03</dd><dt><span>name :</span></dt><dd>flux_loop_flux</dd><dt><span>uda_name :</span></dt><dd>AMB_FL/CC03</dd><dt><span>units :</span></dt><dd>Wb</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[180289466 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>b_field_pol_probe_obv_field</span></div><div class='xr-var-dims'>(time, b_field_pol_probe_obv_channel)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-a504cddf-60ba-4597-a49e-571f64edca6c' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-a504cddf-60ba-4597-a49e-571f64edca6c' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1b6f14f1-8e8d-49de-af59-a3dd88f2648a' class='xr-var-data-in' type='checkbox'><label for='data-1b6f14f1-8e8d-49de-af59-a3dd88f2648a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>description :</span></dt><dd>Outer Bv array</dd><dt><span>imas :</span></dt><dd>magnetics.b_field_pol_probe[:].field.data</dd><dt><span>label :</span></dt><dd>OBV01</dd><dt><span>name :</span></dt><dd>b_field_pol_probe_obv_field</dd><dt><span>uda_name :</span></dt><dd>AMB_OBV01</dd><dt><span>units :</span></dt><dd>T</dd><dt><span>group :</span></dt><dd>magnetics</dd></dl></div><div class='xr-var-data'><pre>[218922923 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>shot_index</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-50b2809c-787c-4303-a49f-24b25d8df822' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-50b2809c-787c-4303-a49f-24b25d8df822' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a548ead0-3da3-405f-9de4-102fd4de1d42' class='xr-var-data-in' type='checkbox'><label for='data-a548ead0-3da3-405f-9de4-102fd4de1d42' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[12877819 values with dtype=int64]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-8fee6688-cb76-42d6-8bc8-b08165cf5b8f' class='xr-section-summary-in' type='checkbox'  ><label for='section-8fee6688-cb76-42d6-8bc8-b08165cf5b8f' class='xr-section-summary' >Indexes: <span>(6)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>b_field_tor_probe_saddle_voltage_channel</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-3a87c400-aa53-4b36-bf67-a41929ec21ea' class='xr-index-data-in' type='checkbox'/><label for='index-3a87c400-aa53-4b36-bf67-a41929ec21ea' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;XMB_SAD/OUT/M01&#x27;, &#x27;XMB_SAD/OUT/M02&#x27;, &#x27;XMB_SAD/OUT/M03&#x27;,\n",
       "       &#x27;XMB_SAD/OUT/M04&#x27;, &#x27;XMB_SAD/OUT/M05&#x27;, &#x27;XMB_SAD/OUT/M06&#x27;,\n",
       "       &#x27;XMB_SAD/OUT/M07&#x27;, &#x27;XMB_SAD/OUT/M08&#x27;, &#x27;XMB_SAD/OUT/M09&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;b_field_tor_probe_saddle_voltage_channel&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-448b65fc-0169-4211-a022-7d1a49295be3' class='xr-index-data-in' type='checkbox'/><label for='index-448b65fc-0169-4211-a022-7d1a49295be3' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-0.06920000165700912, -0.06895000165700912, -0.06870000165700912,\n",
       "       -0.06845000165700912, -0.06820000165700912, -0.06795000165700912,\n",
       "       -0.06770000165700912, -0.06745000165700912, -0.06720000165700912,\n",
       "       -0.06695000165700912,\n",
       "       ...\n",
       "           0.38984995174408,     0.39009995174408,  0.39034995174408005,\n",
       "           0.39059995174408,     0.39084995174408,     0.39109995174408,\n",
       "        0.39134995174408005,     0.39159995174408,     0.39184995174408,\n",
       "           0.39209995174408],\n",
       "      dtype=&#x27;float64&#x27;, name=&#x27;time&#x27;, length=12877819))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>b_field_pol_probe_obr_channel</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-b906f727-4e5c-4559-8057-292b13598f6c' class='xr-index-data-in' type='checkbox'/><label for='index-b906f727-4e5c-4559-8057-292b13598f6c' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;AMB_OBR01&#x27;, &#x27;AMB_OBR02&#x27;, &#x27;AMB_OBR03&#x27;, &#x27;AMB_OBR04&#x27;, &#x27;AMB_OBR05&#x27;,\n",
       "       &#x27;AMB_OBR06&#x27;, &#x27;AMB_OBR07&#x27;, &#x27;AMB_OBR08&#x27;, &#x27;AMB_OBR09&#x27;, &#x27;AMB_OBR10&#x27;,\n",
       "       &#x27;AMB_OBR11&#x27;, &#x27;AMB_OBR12&#x27;, &#x27;AMB_OBR13&#x27;, &#x27;AMB_OBR14&#x27;, &#x27;AMB_OBR15&#x27;,\n",
       "       &#x27;AMB_OBR16&#x27;, &#x27;AMB_OBR17&#x27;, &#x27;AMB_OBR18&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;b_field_pol_probe_obr_channel&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>b_field_pol_probe_ccbv_channel</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-341b06d2-efbc-47e1-8fa0-518dbd2d6661' class='xr-index-data-in' type='checkbox'/><label for='index-341b06d2-efbc-47e1-8fa0-518dbd2d6661' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;AMB_CCBV01&#x27;, &#x27;AMB_CCBV02&#x27;, &#x27;AMB_CCBV03&#x27;, &#x27;AMB_CCBV04&#x27;, &#x27;AMB_CCBV05&#x27;,\n",
       "       &#x27;AMB_CCBV06&#x27;, &#x27;AMB_CCBV07&#x27;, &#x27;AMB_CCBV08&#x27;, &#x27;AMB_CCBV09&#x27;, &#x27;AMB_CCBV11&#x27;,\n",
       "       &#x27;AMB_CCBV12&#x27;, &#x27;AMB_CCBV14&#x27;, &#x27;AMB_CCBV15&#x27;, &#x27;AMB_CCBV16&#x27;, &#x27;AMB_CCBV17&#x27;,\n",
       "       &#x27;AMB_CCBV18&#x27;, &#x27;AMB_CCBV19&#x27;, &#x27;AMB_CCBV20&#x27;, &#x27;AMB_CCBV21&#x27;, &#x27;AMB_CCBV23&#x27;,\n",
       "       &#x27;AMB_CCBV24&#x27;, &#x27;AMB_CCBV25&#x27;, &#x27;AMB_CCBV26&#x27;, &#x27;AMB_CCBV27&#x27;, &#x27;AMB_CCBV28&#x27;,\n",
       "       &#x27;AMB_CCBV29&#x27;, &#x27;AMB_CCBV30&#x27;, &#x27;AMB_CCBV31&#x27;, &#x27;AMB_CCBV32&#x27;, &#x27;AMB_CCBV33&#x27;,\n",
       "       &#x27;AMB_CCBV34&#x27;, &#x27;AMB_CCBV35&#x27;, &#x27;AMB_CCBV36&#x27;, &#x27;AMB_CCBV37&#x27;, &#x27;AMB_CCBV38&#x27;,\n",
       "       &#x27;AMB_CCBV39&#x27;, &#x27;AMB_CCBV40&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;b_field_pol_probe_ccbv_channel&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>flux_loop_channel</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-ec8b1348-a400-4a84-b595-7f6ea611b5d8' class='xr-index-data-in' type='checkbox'/><label for='index-ec8b1348-a400-4a84-b595-7f6ea611b5d8' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;AMB_FL/CC03&#x27;, &#x27;AMB_FL/CC04&#x27;, &#x27;AMB_FL/CC05&#x27;, &#x27;AMB_FL/CC07&#x27;,\n",
       "       &#x27;AMB_FL/CC09&#x27;, &#x27;AMB_FL/P3L/4&#x27;, &#x27;AMB_FL/P3U/1&#x27;, &#x27;AMB_FL/P3U/4&#x27;,\n",
       "       &#x27;AMB_FL/P4L/1&#x27;, &#x27;AMB_FL/P4L/4&#x27;, &#x27;AMB_FL/P4U/4&#x27;, &#x27;AMB_FL/P5L/1&#x27;,\n",
       "       &#x27;AMB_FL/P5L/4&#x27;, &#x27;AMB_FL/P5U/1&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;flux_loop_channel&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>b_field_pol_probe_obv_channel</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-fb38f6f9-526d-48d5-8e4c-4284a0f566c9' class='xr-index-data-in' type='checkbox'/><label for='index-fb38f6f9-526d-48d5-8e4c-4284a0f566c9' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;AMB_OBV01&#x27;, &#x27;AMB_OBV02&#x27;, &#x27;AMB_OBV03&#x27;, &#x27;AMB_OBV04&#x27;, &#x27;AMB_OBV05&#x27;,\n",
       "       &#x27;AMB_OBV06&#x27;, &#x27;AMB_OBV07&#x27;, &#x27;AMB_OBV08&#x27;, &#x27;AMB_OBV09&#x27;, &#x27;AMB_OBV11&#x27;,\n",
       "       &#x27;AMB_OBV12&#x27;, &#x27;AMB_OBV13&#x27;, &#x27;AMB_OBV14&#x27;, &#x27;AMB_OBV15&#x27;, &#x27;AMB_OBV16&#x27;,\n",
       "       &#x27;AMB_OBV17&#x27;, &#x27;AMB_OBV18&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;b_field_pol_probe_obv_channel&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-51e5b6ba-637c-43cc-b944-ba040eaca395' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-51e5b6ba-637c-43cc-b944-ba040eaca395' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset> Size: 10GB\n",
       "Dimensions:                                   (time: 12877819,\n",
       "                                               b_field_tor_probe_saddle_voltage_channel: 9,\n",
       "                                               b_field_pol_probe_obr_channel: 18,\n",
       "                                               b_field_pol_probe_ccbv_channel: 37,\n",
       "                                               flux_loop_channel: 14,\n",
       "                                               b_field_pol_probe_obv_channel: 17)\n",
       "Coordinates:\n",
       "  * b_field_tor_probe_saddle_voltage_channel  (b_field_tor_probe_saddle_voltage_channel) <U15 540B ...\n",
       "  * time                                      (time) float64 103MB -0.0692 .....\n",
       "  * b_field_pol_probe_obr_channel             (b_field_pol_probe_obr_channel) <U9 648B ...\n",
       "  * b_field_pol_probe_ccbv_channel            (b_field_pol_probe_ccbv_channel) <U10 1kB ...\n",
       "  * flux_loop_channel                         (flux_loop_channel) <U12 672B '...\n",
       "  * b_field_pol_probe_obv_channel             (b_field_pol_probe_obv_channel) <U9 612B ...\n",
       "Data variables:\n",
       "    b_field_tor_probe_saddle_voltage          (time, b_field_tor_probe_saddle_voltage_channel) float64 927MB ...\n",
       "    b_field_pol_probe_obr_field               (time, b_field_pol_probe_obr_channel) float64 2GB ...\n",
       "    ip                                        (time) float64 103MB ...\n",
       "    b_field_pol_probe_ccbv_field              (time, b_field_pol_probe_ccbv_channel) float64 4GB ...\n",
       "    flux_loop_flux                            (time, flux_loop_channel) float64 1GB ...\n",
       "    b_field_pol_probe_obv_field               (time, b_field_pol_probe_obv_channel) float64 2GB ...\n",
       "    shot_index                                (time) int64 103MB ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path().absolute().parent.parent / \"data/preprocessed/mscred/data_magnetics_mscred_cleaned.nc\"\n",
    "data_all = xr.open_dataset(path)\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0c26f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0 ... 6117 6117 6117]\n",
      "[2084 1989 2230 ... 3153 2089 1947]\n",
      "Sequence lengths: (6118,)\n",
      "None null values: (6116,)\n",
      "Index where null values: [ 557 2874]\n",
      "[2116 2016 1970  855 1634 1663 2193    0 2193  891]\n",
      "[2082 1636 1648  982    0 1875 1699 2439 5635 1749]\n"
     ]
    }
   ],
   "source": [
    "def find_seq_length(data: xr.Dataset) -> np.ndarray:\n",
    "    # Find the length of each sequence in the dataset\n",
    "    seq_indices = data['shot_index'].values\n",
    "    return np.bincount(seq_indices)\n",
    "\n",
    "lengths = find_seq_length(data_all)\n",
    "print(data_all['shot_index'].values)\n",
    "print(lengths)\n",
    "print(\"Sequence lengths:\", lengths.shape)\n",
    "print(\"None null values:\", lengths[lengths > 0].shape)\n",
    "print(\"Index where null values:\", np.where(lengths == 0)[0])\n",
    "print(lengths[550: 560])\n",
    "print(lengths[2870: 2880])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8628536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateTimeSerieDataset(Dataset):\n",
    "    def __init__(self, data: xr.Dataset, n_chan_to_keep: int = 4, n_subsample: int = 10, max_length: int = 3000):\n",
    "        # Group data by shot_index\n",
    "        self.shot_indices = data['shot_index'].values\n",
    "        self.unique_shots = np.unique(self.shot_indices)\n",
    "        \n",
    "        # Precompute sequences for each shot index\n",
    "        self.sequences = {}\n",
    "        for shot in self.unique_shots:\n",
    "            mask = self.shot_indices == shot\n",
    "            shot_data = []\n",
    "            for var in data.data_vars:\n",
    "                if var == 'shot_index':\n",
    "                    continue\n",
    "\n",
    "                if data[var].ndim == 1:\n",
    "                    var_data = data[var].values[mask][:, np.newaxis]\n",
    "                    if len(var_data) > max_length:\n",
    "                        var_data = var_data[:max_length]\n",
    "\n",
    "                else:\n",
    "                    var_data = data[var].values[mask]\n",
    "                    if var_data.shape[1] > n_chan_to_keep:\n",
    "                        var_data = var_data[:, :n_chan_to_keep]\n",
    "                    if len(var_data) > max_length:\n",
    "                        var_data = var_data[:max_length]\n",
    "                        \n",
    "                var_data = var_data[::n_subsample]\n",
    "                shot_data.append(var_data)\n",
    "            self.sequences[shot] = np.concatenate(shot_data, axis=1)      # axis=1 => along features dimension\n",
    "        \n",
    "        self.lengths = {shot: len(self.sequences[shot]) for shot in self.unique_shots}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_shots)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        shot = self.unique_shots[idx]\n",
    "        return self.sequences[shot], self.lengths[shot]\n",
    "    \n",
    "class OneVariableTimeSerieDataset(Dataset):\n",
    "    def __init__(self, data: xr.Dataset, var_name: str = \"ip\", chan_to_keep: None | int = 1, n_subsample: int = 12, max_length: int = 3000):\n",
    "        # Group data by shot_index\n",
    "        self.shot_indices = data['shot_index'].values\n",
    "        self.unique_shots = np.unique(self.shot_indices)\n",
    "        \n",
    "        # Precompute sequences for each shot index\n",
    "        self.sequences = {}\n",
    "        for shot in self.unique_shots:\n",
    "            mask = self.shot_indices == shot\n",
    "            data_var = data[var_name].values[mask]\n",
    "            if data_var.ndim > 1:\n",
    "                data_var = data_var[:, chan_to_keep]\n",
    "            if len(data_var) > max_length:\n",
    "                data_var = data_var[:max_length] \n",
    "            data_var = data_var[::n_subsample]\n",
    "            self.sequences[shot] = data_var[:, np.newaxis]  # Add feature dimension\n",
    "\n",
    "        self.lengths = {shot: len(self.sequences[shot]) for shot in self.unique_shots}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_shots)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        shot = self.unique_shots[idx]\n",
    "        return self.sequences[shot], self.lengths[shot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4bbaf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(\n",
    "    data: xr.Dataset,\n",
    "    set_separation: int = 12000,\n",
    "    total_length: int = 3500,\n",
    "    rd_seed: int = 42\n",
    ") -> tuple[Dataset]:\n",
    "    \"\"\"\n",
    "    Create train, validation and test data loaders from time series data\n",
    "    \n",
    "    Args:\n",
    "        data: xarray Dataset with shot_index variable\n",
    "        batch_size: batch size for data loaders\n",
    "        set_separation: boundarie between train and test sets\n",
    "        device: device to load data on\n",
    "    \n",
    "    Returns:\n",
    "        train_loader, valid_loader, test_loader: DataLoader objects\n",
    "    \"\"\"\n",
    "    data = data.isel(time=slice(0, total_length))\n",
    "\n",
    "    shot_indices = data['shot_index'].values\n",
    "    seq_lengths = np.bincount(shot_indices)\n",
    "    unique_shots = np.unique(shot_indices)\n",
    "    available_shots = unique_shots.copy()\n",
    "\n",
    "    print(\"unique shots:\", unique_shots.shape)\n",
    "\n",
    "    rng = np.random.default_rng(rd_seed)\n",
    "\n",
    "    test_shot_indices = []\n",
    "    cumulative_time = 0\n",
    "\n",
    "    while (cumulative_time < total_length - set_separation):\n",
    "        shot_idx = rng.choice(available_shots, size=1, replace=False)[0]\n",
    "        available_shots = available_shots[available_shots != shot_idx]\n",
    "\n",
    "        shot_length = seq_lengths[shot_idx]\n",
    "        test_shot_indices.append(shot_idx)\n",
    "        cumulative_time += shot_length\n",
    "\n",
    "    train_shot_indices = list(available_shots)\n",
    "    print(\"Train shots:\", len(train_shot_indices), \"Test shots:\", len(test_shot_indices))\n",
    "    assert len(train_shot_indices) + len(test_shot_indices) == len(unique_shots), \"Some shots are missing in the split\"\n",
    "\n",
    "    train_mask = np.isin(shot_indices, train_shot_indices)\n",
    "    test_mask = np.isin(shot_indices, test_shot_indices)\n",
    "    print(\"Train samples:\", train_mask.sum(), \"Test samples:\", test_mask.sum())\n",
    "\n",
    "    # Create datasets for each split\n",
    "    train_dataset = OneVariableTimeSerieDataset(data.isel(time=train_mask), var_name=\"ip\", chan_to_keep=None, n_subsample=25, max_length=3000)\n",
    "    test_dataset = OneVariableTimeSerieDataset(data.isel(time=test_mask), var_name=\"ip\", chan_to_keep=None, n_subsample=25, max_length=3000)\n",
    "    # train_dataset = MultivariateTimeSerieDataset(data.isel(time=train_mask), n_chan_to_keep=4, n_subsample=12, max_length=3000)\n",
    "    # test_dataset = MultivariateTimeSerieDataset(data.isel(time=test_mask), n_chan_to_keep=4, n_subsample=12, max_length=3000)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764de3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average running time: 5min 30sec\n",
    "\n",
    "train_set, test_set = create_datasets(data_all, set_separation=config.SET_SEPARATION, total_length=config.DATA_NUMBER, rd_seed=config.SEED)\n",
    "\n",
    "print(\"Training set size:\", len(train_set))\n",
    "print(\"Testing set size:\", len(test_set))\n",
    "print(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ee387",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = config.DIR_PREPROCESSED_DATA / f\"dataset_raw_vae_train.pt\"\n",
    "path_test = config.DIR_PREPROCESSED_DATA / f\"dataset_raw_vae_test.pt\"\n",
    "if not path_train.exists():\n",
    "    torch.save(train_set, path_train)\n",
    "    print(f\"Saved dataset to {path_train}\")\n",
    "if not path_test.exists():\n",
    "    torch.save(test_set, path_test)\n",
    "    print(f\"Saved dataset to {path_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1771412",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1007415/2784269247.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_set = torch.load(path_train)\n",
      "/tmp/ipykernel_1007415/2784269247.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_set = torch.load(path_test)\n"
     ]
    }
   ],
   "source": [
    "path_train = config.DIR_PREPROCESSED_DATA / f\"dataset_ip_vae_train.pt\"\n",
    "path_test = config.DIR_PREPROCESSED_DATA / f\"dataset_ip_vae_test.pt\"\n",
    "train_set = torch.load(path_train)\n",
    "test_set = torch.load(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e712bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences_smartly(batch):\n",
    "    \"\"\"Custom collate function to pad sequences to max length in batch\"\"\"\n",
    "    sequences, lengths = zip(*batch)\n",
    "    \n",
    "    # Convert sequences to tensors\n",
    "    sequence_tensors = [torch.from_numpy(seq).float() for seq in sequences]\n",
    "    padded_sequences = pad_sequence(\n",
    "        sequence_tensors, \n",
    "        batch_first=True, \n",
    "        padding_value=0.0\n",
    "    )\n",
    "    length_tensor = torch.tensor(lengths, dtype=torch.long)\n",
    "    \n",
    "    return padded_sequences, length_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4061920d",
   "metadata": {},
   "source": [
    "## 2. Model LSTM-$\\beta$-VAE implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd66d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"Embedding dimension must be divisible by number of heads\"\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        \n",
    "        # Projection layers for queries, keys and values\n",
    "        self.q_proj = nn.Linear(input_dim, embed_dim)\n",
    "        self.k_proj = nn.Linear(input_dim, embed_dim)\n",
    "        self.v_proj = nn.Linear(input_dim, embed_dim)\n",
    "        \n",
    "        self.output_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = np.sqrt(self.head_dim)\n",
    "        \n",
    "    def forward(self, query, key, value, key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        query: [batch_size, query_len, input_dim]\n",
    "        key: [batch_size, key_len, input_dim]\n",
    "        value: [batch_size, value_len, input_dim]\n",
    "        key_padding_mask: [batch_size, key_len] (True for padding positions)\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "        query_len = query.size(1)\n",
    "        key_len = key.size(1)\n",
    "        \n",
    "        # Project queries, keys and values\n",
    "        Q = self.q_proj(query)  # [batch_size, query_len, embed_dim]\n",
    "        K = self.k_proj(key)    # [batch_size, key_len, embed_dim]\n",
    "        V = self.v_proj(value)  # [batch_size, value_len, embed_dim]\n",
    "        \n",
    "        # Reshape for multi-head attention\n",
    "        Q = Q.view(batch_size, query_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(batch_size, key_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(batch_size, key_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Calculate attention scores\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale  # [batch_size, num_heads, query_len, key_len]\n",
    "        \n",
    "        # Apply mask if provided\n",
    "        if key_padding_mask is not None:\n",
    "            # Expand mask to [batch_size, num_heads, query_len, key_len]\n",
    "            mask = key_padding_mask.unsqueeze(1).unsqueeze(2).expand(-1, self.num_heads, query_len, -1)\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "        \n",
    "        # Apply softmax to get attention weights\n",
    "        attn_weights = nn.functional.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        attn_output = torch.matmul(attn_weights, V)  # [batch_size, num_heads, query_len, head_dim]\n",
    "        \n",
    "        # Concatenate heads and put through final linear layer\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, query_len, self.embed_dim)\n",
    "        attn_output = self.output_proj(attn_output)\n",
    "        \n",
    "        return attn_output, attn_weights\n",
    "    \n",
    "class MultiHeadAttention2(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        \n",
    "        self.q_proj = nn.Linear(dim, dim)\n",
    "        self.k_proj = nn.Linear(dim, dim)\n",
    "        self.v_proj = nn.Linear(dim, dim)\n",
    "        self.out_proj = nn.Linear(dim, dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # Projections linéaires\n",
    "        Q = self.q_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        K = self.k_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        V = self.v_proj(x).view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Calcul d'attention par tête\n",
    "        scores = torch.einsum('bqhd,bkhd->bhqk', Q, K) / math.sqrt(self.head_dim)\n",
    "        attention = torch.softmax(scores, dim=-1)\n",
    "        out = torch.einsum('bhqk,bkhd->bqhd', attention, V)\n",
    "        \n",
    "        # Concaténation et projection finale\n",
    "        out = out.contiguous().view(batch_size, seq_len, -1)\n",
    "        return self.out_proj(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1dbf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeAttentionEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Attention sur la sortie LSTM\n",
    "        self.attention = MultiHeadAttention(\n",
    "            input_dim=hidden_dim * 2,\n",
    "            embed_dim=hidden_dim * 2, \n",
    "            num_heads=num_heads\n",
    "        )\n",
    "        \n",
    "        # Couches pour produire mean et logvar\n",
    "        self.to_mean = nn.Linear(hidden_dim * 2, latent_dim)\n",
    "        self.to_logvar = nn.Linear(hidden_dim * 2, latent_dim)\n",
    "        \n",
    "    def forward(self, x, lengths):\n",
    "        # 1. LSTM\n",
    "        packed_input = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        lstm_output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        # 2. Masque pour l'attention\n",
    "        mask = torch.arange(x.size(1), device=x.device)[None, :] >= lengths[:, None]\n",
    "        \n",
    "        # 3. Auto-attention sur la sortie LSTM\n",
    "        attn_output, attn_weights = self.attention(\n",
    "            query=lstm_output, \n",
    "            key=lstm_output, \n",
    "            value=lstm_output,\n",
    "            key_padding_mask=mask\n",
    "        )\n",
    "        \n",
    "        # 4. Pooling global (seulement sur les steps valides)\n",
    "        mask_expanded = mask.unsqueeze(-1)\n",
    "        summed = torch.sum(attn_output * (~mask_expanded).float(), dim=1)\n",
    "        context = summed / lengths.float().unsqueeze(-1)\n",
    "        \n",
    "        # 5. Transformation en vecteur latent\n",
    "        z_mean = self.to_mean(context)\n",
    "        z_logvar = self.to_logvar(context)\n",
    "        \n",
    "        return z_mean, z_logvar, attn_weights\n",
    "\n",
    "class SafeAttentionDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim, num_layers, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.latent_to_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Pas d'attention croisée avec l'encodeur pour éviter la fuite!\n",
    "        \n",
    "    def forward(self, z, lengths):\n",
    "        batch_size = z.size(0)\n",
    "        max_length = lengths.max()\n",
    "        \n",
    "        # Initialisation à partir du vecteur latent\n",
    "        h0 = self.latent_to_hidden(z).unsqueeze(0).repeat(self.lstm.num_layers, 1, 1)\n",
    "        c0 = torch.zeros_like(h0)\n",
    "        \n",
    "        # Séquence d'entrée nulle\n",
    "        input_seq = torch.zeros(batch_size, max_length, self.lstm.input_size, device=z.device)\n",
    "        \n",
    "        # LSTM\n",
    "        packed_input = pack_padded_sequence(input_seq, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, _ = self.lstm(packed_input, (h0, c0))\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        \n",
    "        return self.output_layer(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4b5684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LengthAwareLSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, latent_dim: int, num_layers: int) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder_lstm = nn.LSTM(input_dim, hidden_dim, num_layers, bidirectional=False, batch_first=True)\n",
    "        self.encoder_linear_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.encoder_linear_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        #self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x_padded: torch.Tensor, lengths: torch.Tensor, hidden: tuple = None) -> tuple[torch.Tensor]:\n",
    "        if hidden is None:\n",
    "            h0 = torch.zeros(self.encoder_lstm.num_layers, x_padded.size(0), self.encoder_lstm.hidden_size, device=x_padded.device)\n",
    "            c0 = torch.zeros(self.encoder_lstm.num_layers, x_padded.size(0), self.encoder_lstm.hidden_size, device=x_padded.device)\n",
    "            hidden = (h0, c0)\n",
    "\n",
    "        packed_input = pack_padded_sequence(x_padded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, hidden = self.encoder_lstm(packed_input)\n",
    "        #output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "        last_hidden = hidden[0][-1]\n",
    "        mean = self.encoder_linear_mean(last_hidden)\n",
    "        logvar = self.encoder_linear_logvar(last_hidden)\n",
    "        return mean, logvar, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b38617b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "input_dim = 24\n",
    "hidden_dim = 128\n",
    "latent_dim = 24\n",
    "num_layers = 2\n",
    "\n",
    "n_time = 200\n",
    "length_foo = torch.randint(low=50, high=n_time+1, size=(batch_size,))\n",
    "seq_length = max(length_foo).item()\n",
    "x_foo = torch.randn(batch_size, seq_length, input_dim)\n",
    "encoder_foo = LengthAwareLSTMEncoder(input_dim, hidden_dim, latent_dim, num_layers)\n",
    "mean_foo, logvar_foo, (h_final, c_final) = encoder_foo(x_foo, length_foo)\n",
    "\n",
    "\n",
    "assert mean_foo.shape == (batch_size, latent_dim)\n",
    "assert logvar_foo.shape == (batch_size, latent_dim)\n",
    "assert h_final.shape == (num_layers, batch_size, hidden_dim)\n",
    "assert c_final.shape == (num_layers, batch_size, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a318bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LengthAwareLSTMDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim: int, hidden_dim: int, output_dim: int, num_layers: int) -> None:\n",
    "        super().__init__()\n",
    "        self.decoder_linear_init = nn.Linear(latent_dim, hidden_dim * num_layers * 2)  # For hidden and cell states of each layer\n",
    "        self.decoder_lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, bidirectional=False, batch_first=True)\n",
    "        self.decoder_output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        #self.dropout = nn.Dropout(p=0.5)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, z: torch.Tensor, lengths: torch.Tensor, hidden: tuple = None) -> torch.Tensor:\n",
    "        batch_size = z.size(0)\n",
    "\n",
    "        if hidden is None:\n",
    "            init_states = self.decoder_linear_init(z)\n",
    "            h0 = init_states[:, :self.hidden_dim * self.num_layers].reshape(self.num_layers, batch_size, self.hidden_dim)\n",
    "            c0 = init_states[:, self.hidden_dim * self.num_layers:].reshape(self.num_layers, batch_size, self.hidden_dim)\n",
    "            hidden = (h0, c0)\n",
    "\n",
    "        max_length = torch.max(lengths)\n",
    "        input_seq = torch.zeros(batch_size, max_length, self.hidden_dim, device=z.device)\n",
    "\n",
    "        packed_input = pack_padded_sequence(input_seq, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_output, hidden_out = self.decoder_lstm(packed_input, hidden)\n",
    "\n",
    "        transformed_data = self.decoder_output_layer(packed_output.data)\n",
    "        output_packed = torch.nn.utils.rnn.PackedSequence(\n",
    "            data=transformed_data, \n",
    "            batch_sizes=packed_output.batch_sizes,\n",
    "            sorted_indices=packed_output.sorted_indices,\n",
    "            unsorted_indices=packed_output.unsorted_indices\n",
    "        )\n",
    "        output, _ = pad_packed_sequence(output_packed, batch_first=True)\n",
    "\n",
    "        return output, hidden_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9531e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "seq_length = 200\n",
    "input_dim = 24\n",
    "hidden_dim = 128\n",
    "latent_dim = 24\n",
    "num_layers = 2\n",
    "\n",
    "z_foo = torch.randn(batch_size, latent_dim)\n",
    "decoder_foo = LengthAwareLSTMDecoder(latent_dim, hidden_dim, input_dim, num_layers)\n",
    "masked_output_foo, (h_out, c_out) = decoder_foo(z_foo, length_foo)\n",
    "\n",
    "assert masked_output_foo.shape == (batch_size, torch.max(length_foo), input_dim)\n",
    "assert h_out.shape == (num_layers, batch_size, hidden_dim)\n",
    "assert c_out.shape == (num_layers, batch_size, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6eeada8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBetaVAE(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int, latent_dim: int, lstm_num_layers: int, bptt_steps: int = 20) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = LengthAwareLSTMEncoder(input_dim, hidden_dim, latent_dim, lstm_num_layers)\n",
    "        self.decoder = LengthAwareLSTMDecoder(latent_dim, hidden_dim, input_dim, lstm_num_layers)\n",
    "        self.bptt_steps = bptt_steps\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, lengths: torch.Tensor) -> tuple[torch.Tensor]:\n",
    "        _, seq_len, _ = x.shape\n",
    "        reconstructions = []\n",
    "        all_z_means = []\n",
    "        all_z_logvars = []\n",
    "        \n",
    "        # Initialization\n",
    "        h_enc, c_enc = None, None\n",
    "        h_dec, c_dec = None, None\n",
    "        \n",
    "        for start_idx in range(0, seq_len, self.bptt_steps):\n",
    "            end_idx = min(start_idx + self.bptt_steps, seq_len)\n",
    "            segment = x[:, start_idx:end_idx, :]\n",
    "            \n",
    "            if h_enc is not None:\n",
    "                h_enc, c_enc = h_enc.detach(), c_enc.detach()\n",
    "            if h_dec is not None:\n",
    "                h_dec, c_dec = h_dec.detach(), c_dec.detach()\n",
    "            \n",
    "            z_mean_segment, z_logvar_segment, (h_enc, c_enc) = self.encoder(segment, lengths, (h_enc, c_enc))\n",
    "            all_z_means.append(z_mean_segment)\n",
    "            all_z_logvars.append(z_logvar_segment)\n",
    "            z_segment = self.reparameterize(z_mean_segment, z_logvar_segment)\n",
    "            \n",
    "            x_reconstructed, (h_dec, c_dec) = self.decoder(z_segment, lengths, (h_dec, c_dec))\n",
    "            reconstructions.append(x_reconstructed)\n",
    "\n",
    "        z_means_all = torch.stack(all_z_means, dim=1)  # [batch, segments, latent_dim]\n",
    "        z_logvars_all = torch.stack(all_z_logvars, dim=1)\n",
    "        z_mean = torch.mean(z_means_all, dim=1)\n",
    "        z_logvar = torch.mean(z_logvars_all, dim=1)\n",
    "        reconstruction = torch.cat(reconstructions, dim=1)\n",
    "        return reconstruction, z_mean, z_logvar\n",
    "\n",
    "    def reparameterize(self, mean: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bc3216c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "start (200) + length (10) exceeds dimension size (200).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m x_foo = torch.randn(batch_size, seq_length, input_dim)\n\u001b[32m     11\u001b[39m vae_foo = LSTMBetaVAE(input_dim, hidden_dim, latent_dim, num_layers)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m output_foo, mean_foo, logvar_foo = \u001b[43mvae_foo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_foo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength_foo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m mean_foo.shape == (batch_size, latent_dim)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m logvar_foo.shape == (batch_size, latent_dim)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mLSTMBetaVAE.forward\u001b[39m\u001b[34m(self, x, lengths)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m h_dec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     25\u001b[39m     h_dec, c_dec = h_dec.detach(), c_dec.detach()\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m z_mean_segment, z_logvar_segment, (h_enc, c_enc) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_enc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_enc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m all_z_means.append(z_mean_segment)\n\u001b[32m     29\u001b[39m all_z_logvars.append(z_logvar_segment)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mLengthAwareLSTMEncoder.forward\u001b[39m\u001b[34m(self, x_padded, lengths, hidden)\u001b[39m\n\u001b[32m     13\u001b[39m     hidden = (h0, c0)\n\u001b[32m     15\u001b[39m packed_input = pack_padded_sequence(x_padded, lengths.cpu(), batch_first=\u001b[38;5;28;01mTrue\u001b[39;00m, enforce_sorted=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m packed_output, hidden = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder_lstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m#output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)\u001b[39;00m\n\u001b[32m     19\u001b[39m last_hidden = hidden[\u001b[32m0\u001b[39m][-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:920\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m    917\u001b[39m     result = _VF.lstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m._flat_weights, \u001b[38;5;28mself\u001b[39m.bias, \u001b[38;5;28mself\u001b[39m.num_layers,\n\u001b[32m    918\u001b[39m                       \u001b[38;5;28mself\u001b[39m.dropout, \u001b[38;5;28mself\u001b[39m.training, \u001b[38;5;28mself\u001b[39m.bidirectional, \u001b[38;5;28mself\u001b[39m.batch_first)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    922\u001b[39m output = result[\u001b[32m0\u001b[39m]\n\u001b[32m    923\u001b[39m hidden = result[\u001b[32m1\u001b[39m:]\n",
      "\u001b[31mRuntimeError\u001b[39m: start (200) + length (10) exceeds dimension size (200)."
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "input_dim = 24\n",
    "hidden_dim = 128\n",
    "latent_dim = 24\n",
    "num_layers = 2\n",
    "\n",
    "n_time = 200\n",
    "length_foo = torch.randint(low=100, high=n_time+1, size=(batch_size,))\n",
    "seq_length = max(length_foo).item()\n",
    "x_foo = torch.randn(batch_size, seq_length, input_dim)\n",
    "vae_foo = LSTMBetaVAE(input_dim, hidden_dim, latent_dim, num_layers)\n",
    "output_foo, mean_foo, logvar_foo = vae_foo(x_foo, length_foo)\n",
    "\n",
    "\n",
    "assert mean_foo.shape == (batch_size, latent_dim)\n",
    "assert logvar_foo.shape == (batch_size, latent_dim)\n",
    "assert output_foo.shape == (batch_size, torch.max(length_foo), input_dim)\n",
    "assert output_foo.shape == x_foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7975cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_function(\n",
    "    x_recon: torch.Tensor, \n",
    "    x: torch.Tensor, \n",
    "    z_mean: torch.Tensor, \n",
    "    z_logvar: torch.Tensor, \n",
    "    lengths: torch.Tensor, \n",
    "    beta: float = 1.0\n",
    "    ) -> tuple[torch.Tensor]:\n",
    "\n",
    "    _, seq_length, _ = x.shape\n",
    "\n",
    "    mask = torch.arange(seq_length, device=x_recon.device)[None, :] < lengths[:, None]      # shape [batch_size, max_length]\n",
    "    mask = mask.unsqueeze(-1).float()                                                       # shape [batch_size, max_length, 1]\n",
    "\n",
    "    MSE = nn.functional.mse_loss(x_recon, x, reduction='none')\n",
    "    MSE = (MSE * mask).sum(dim=(1,2))        # Mask application\n",
    "    num_valid_steps = mask.sum(dim=(1,2))    # Normalizing factor\n",
    "    MSE = torch.where(num_valid_steps > 0, MSE / num_valid_steps, torch.zeros_like(MSE))\n",
    "    KLD = -0.5 * torch.sum(1 + z_logvar - z_mean.pow(2) - z_logvar.exp(), dim=1)\n",
    "\n",
    "    MSE = torch.mean(MSE)\n",
    "    KLD = torch.mean(KLD)\n",
    "    TOTAL = MSE + beta * KLD\n",
    "\n",
    "    return TOTAL, MSE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a16018d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42.6963)\n",
      "tensor(2.0773)\n",
      "tensor(20.3095)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "input_dim = 1\n",
    "hidden_dim = 128\n",
    "latent_dim = 24\n",
    "num_layers = 1\n",
    "\n",
    "n_time = 200\n",
    "length_foo = torch.randint(low=100, high=n_time+1, size=(batch_size,))\n",
    "seq_length = max(length_foo).item()\n",
    "x_foo = torch.randn(batch_size, seq_length, input_dim)\n",
    "x_recon_foo = torch.randn(batch_size, seq_length, input_dim)\n",
    "\n",
    "z_mean_foo = torch.randn(batch_size, latent_dim)\n",
    "z_logvar_foo = torch.randn(batch_size, latent_dim)\n",
    "\n",
    "beta = 2.0\n",
    "\n",
    "loss, loss_mse, loss_kld = vae_loss_function(\n",
    "    x_foo, x_recon_foo, z_mean_foo, z_logvar_foo, length_foo, beta\n",
    ")\n",
    "\n",
    "print(loss)\n",
    "print(loss_mse)\n",
    "print(loss_kld)\n",
    "assert loss.shape == torch.Size([])\n",
    "assert loss_mse.shape == torch.Size([])\n",
    "assert loss_kld.shape == torch.Size([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ffd348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_parameters(model, model_name=\"LSTMBetaVAE\"):\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total_params = 0\n",
    "    for name, module in model.named_children():\n",
    "        if hasattr(module, 'parameters'):\n",
    "            module_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "            print(f\"{name}: {module_params:,} parameters\")\n",
    "            total_params += module_params\n",
    "            \n",
    "            print(\"-\" * 40)\n",
    "            for sub_name, sub_module in module.named_children():\n",
    "                if hasattr(sub_module, 'parameters'):\n",
    "                    sub_params = sum(p.numel() for p in sub_module.parameters() if p.requires_grad)\n",
    "                    print(f\"  ├─ {sub_name}: {sub_params:,} parameters\")\n",
    "                    \n",
    "                    if hasattr(sub_module, 'named_parameters'):\n",
    "                        print(\"  │   └─ Components:\")\n",
    "                        for param_name, param in sub_module.named_parameters():\n",
    "                            if param.requires_grad:\n",
    "                                print(f\"  │      ├─ {param_name}: {param.numel():,} parameters \"\n",
    "                                      f\"(shape: {tuple(param.shape)})\")\n",
    "            print(\"-\" * 40)\n",
    "            print()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total Trainable Parameters: {total_params:,}\")\n",
    "    \n",
    "    print(\"\\nArchitecture Details:\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    if hasattr(model, 'encoder'):\n",
    "        encoder = model.encoder\n",
    "        print(\"Encoder Structure:\")\n",
    "        for name, module in encoder.named_modules():\n",
    "            if isinstance(module, torch.nn.LSTM):\n",
    "                print(f\"  LSTM: input_size={module.input_size}, \"\n",
    "                      f\"hidden_size={module.hidden_size}, \"\n",
    "                      f\"num_layers={module.num_layers}, \"\n",
    "                      f\"bidirectional={module.bidirectional}\")\n",
    "            elif isinstance(module, torch.nn.Linear):\n",
    "                print(f\"  Linear: in_features={module.in_features}, \"\n",
    "                      f\"out_features={module.out_features}\")\n",
    "    \n",
    "    if hasattr(model, 'decoder'):\n",
    "        decoder = model.decoder\n",
    "        print(\"Decoder Structure:\")\n",
    "        for name, module in decoder.named_modules():\n",
    "            if isinstance(module, torch.nn.LSTM):\n",
    "                print(f\"  LSTM: input_size={module.input_size}, \"\n",
    "                      f\"hidden_size={module.hidden_size}, \"\n",
    "                      f\"num_layers={module.num_layers}, \"\n",
    "                      f\"bidirectional={module.bidirectional}\")\n",
    "            elif isinstance(module, torch.nn.Linear):\n",
    "                print(f\"  Linear: in_features={module.in_features}, \"\n",
    "                      f\"out_features={module.out_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78db3c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LSTMBetaVAE\n",
      "============================================================\n",
      "encoder: 5,536 parameters\n",
      "----------------------------------------\n",
      "  ├─ encoder_lstm: 4,480 parameters\n",
      "  │   └─ Components:\n",
      "  │      ├─ weight_ih_l0: 128 parameters (shape: (128, 1))\n",
      "  │      ├─ weight_hh_l0: 4,096 parameters (shape: (128, 32))\n",
      "  │      ├─ bias_ih_l0: 128 parameters (shape: (128,))\n",
      "  │      ├─ bias_hh_l0: 128 parameters (shape: (128,))\n",
      "  ├─ encoder_linear_mean: 528 parameters\n",
      "  │   └─ Components:\n",
      "  │      ├─ weight: 512 parameters (shape: (16, 32))\n",
      "  │      ├─ bias: 16 parameters (shape: (16,))\n",
      "  ├─ encoder_linear_logvar: 528 parameters\n",
      "  │   └─ Components:\n",
      "  │      ├─ weight: 512 parameters (shape: (16, 32))\n",
      "  │      ├─ bias: 16 parameters (shape: (16,))\n",
      "----------------------------------------\n",
      "\n",
      "decoder: 9,569 parameters\n",
      "----------------------------------------\n",
      "  ├─ decoder_linear_init: 1,088 parameters\n",
      "  │   └─ Components:\n",
      "  │      ├─ weight: 1,024 parameters (shape: (64, 16))\n",
      "  │      ├─ bias: 64 parameters (shape: (64,))\n",
      "  ├─ decoder_lstm: 8,448 parameters\n",
      "  │   └─ Components:\n",
      "  │      ├─ weight_ih_l0: 4,096 parameters (shape: (128, 32))\n",
      "  │      ├─ weight_hh_l0: 4,096 parameters (shape: (128, 32))\n",
      "  │      ├─ bias_ih_l0: 128 parameters (shape: (128,))\n",
      "  │      ├─ bias_hh_l0: 128 parameters (shape: (128,))\n",
      "  ├─ decoder_output_layer: 33 parameters\n",
      "  │   └─ Components:\n",
      "  │      ├─ weight: 32 parameters (shape: (1, 32))\n",
      "  │      ├─ bias: 1 parameters (shape: (1,))\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "Total Trainable Parameters: 15,105\n",
      "\n",
      "Architecture Details:\n",
      "----------------------------------------\n",
      "Encoder Structure:\n",
      "  LSTM: input_size=1, hidden_size=32, num_layers=1, bidirectional=False\n",
      "  Linear: in_features=32, out_features=16\n",
      "  Linear: in_features=32, out_features=16\n",
      "Decoder Structure:\n",
      "  Linear: in_features=16, out_features=64\n",
      "  LSTM: input_size=32, hidden_size=32, num_layers=1, bidirectional=False\n",
      "  Linear: in_features=32, out_features=1\n"
     ]
    }
   ],
   "source": [
    "vae_test = LSTMBetaVAE(\n",
    "    input_dim=1,\n",
    "    hidden_dim=32,\n",
    "    latent_dim=16,\n",
    "    lstm_num_layers=1\n",
    ")\n",
    "print_model_parameters(vae_test)\n",
    "\n",
    "del vae_test\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a47b28c",
   "metadata": {},
   "source": [
    "## 3. Train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd62f44f",
   "metadata": {},
   "source": [
    "- On choisit d'éliminer les outliers par rapport à la densité de la reconstruction et non à la clusterisation de l'espace latent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc740d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import gc\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "803a03e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from magnetics_diagnostic_analysis.ml_tools.train_callbacks import EarlyStopping, LRScheduling, GradientClipping, DropOutScheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d85d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_reconstruction_error(\n",
    "    x_recon: torch.Tensor, \n",
    "    x: torch.Tensor, \n",
    "    lengths: torch.Tensor, \n",
    "    ) -> tuple[torch.Tensor]:\n",
    "\n",
    "    _, seq_length, _ = x.shape\n",
    "\n",
    "    mask = torch.arange(seq_length, device=x_recon.device)[None, :] < lengths[:, None]      # shape [batch_size, max_length]\n",
    "    mask = mask.unsqueeze(-1).float()                                                       # shape [batch_size, max_length, 1]\n",
    "\n",
    "    mse = nn.functional.mse_loss(x_recon, x, reduction='none')\n",
    "    mse = (mse * mask).sum(dim=(1,2))        # Mask application\n",
    "    num_valid_steps = mask.sum(dim=(1,2))    # Normalizing factor\n",
    "    mse = torch.where(num_valid_steps > 0, mse / num_valid_steps, torch.zeros_like(mse))\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a9c6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_vae(model, optimizer, loader, full_loader, n_epochs_per_iter, device, verbose):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    if verbose:\n",
    "        print(f\"{'Epoch':<40} {'Loss':<20} {'mse':<20} {'kld':<20}\")\n",
    "    for epoch in range(n_epochs_per_iter):\n",
    "        total_loss = 0\n",
    "        for batch_data, batch_lengths in tqdm(loader, desc=f\"Training intermediate VAE\", leave=False):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_lengths = batch_lengths.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, z_mean, z_logvar = model(batch_data, batch_lengths)\n",
    "            loss, mse, kld = vae_loss_function(recon_batch, batch_data, z_mean, z_logvar, batch_lengths, beta=1.1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_mse, total_kld = mse.item(), kld.item()\n",
    "\n",
    "        epo, total_loss, total_mse, total_kld = f\"Iteration {epoch + 1}/{n_epochs_per_iter}\", total_loss/len(loader), total_mse/len(loader), total_kld/len(loader)\n",
    "        if verbose:\n",
    "            print(f\"{epo:<40} {total_loss:<20} {total_mse:<20} {total_kld:<20}\")\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # VAE Evaluation\n",
    "    model.eval()\n",
    "    reconstruction_errors = []           # or len(current_subset)\n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_lengths in tqdm(full_loader, desc=f\"Evaluating intermediate VAE\", leave=False):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_lengths = batch_lengths.to(device)\n",
    "            \n",
    "            recon_batch, _, _ = model(batch_data, batch_lengths)\n",
    "            mse = vae_reconstruction_error(recon_batch, batch_data, batch_lengths)\n",
    "            reconstruction_errors.append(mse.cpu())\n",
    "\n",
    "    reconstruction_errors = torch.cat(reconstruction_errors).numpy()\n",
    "    return reconstruction_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7639e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold_kde(scores, alpha=0.05):\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth='scott')\n",
    "    kde.fit(scores.reshape(-1, 1))\n",
    "\n",
    "    # Method 1: Based on gradient of density \n",
    "    # x = np.linspace(np.min(scores), np.max(scores), 1000)\n",
    "    # log_dens = kde.score_samples(x.reshape(-1, 1))\n",
    "    # density = np.exp(log_dens)\n",
    "    # gradient = np.gradient(density)\n",
    "    # inflection_point = x[np.argmin(gradient)]\n",
    "    # Method 2: Percentile of density\n",
    "    density_values = np.exp(kde.score_samples(scores.reshape(-1, 1)))\n",
    "    threshold_density = np.percentile(density_values, alpha * 100)\n",
    "\n",
    "    threshold = np.percentile(scores[density_values <= threshold_density], (1-alpha)*100)\n",
    "    del kde\n",
    "    return threshold\n",
    "\n",
    "def detect_outliers_kde(scores, alpha=0.05):\n",
    "    threshold = find_threshold_kde(scores, alpha)\n",
    "    outlier_mask = scores > threshold\n",
    "    outlier_indices = np.where(outlier_mask)[0]\n",
    "    \n",
    "    return outlier_indices, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "835d6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_vae(model, optimizer, loader, full_loader, n_epochs_per_iter, device, verbose):\n",
    "\n",
    "    model.train()\n",
    "    if verbose:\n",
    "        print(f\"{'Epoch':<40} {'Loss':<20} {'mse':<20} {'kld':<20}\")\n",
    "    for epoch in range(n_epochs_per_iter):\n",
    "        total_loss = 0\n",
    "        for batch_data, batch_lengths in tqdm(loader, desc=\"Training final VAE\", leave=False):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_lengths = batch_lengths.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, z_mean, z_logvar = model(batch_data, batch_lengths)\n",
    "            loss, mse, kld = vae_loss_function(recon_batch, batch_data, z_mean, z_logvar, batch_lengths, beta=1.1)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_mse, total_kld = mse.item(), kld.item()\n",
    "\n",
    "        epo, total_loss, total_mse, total_kld = f\"Iteration {epoch + 1}/{n_epochs_per_iter}\", total_loss/len(loader), total_mse/len(loader), total_kld/len(loader)\n",
    "        if verbose:\n",
    "            print(f\"{epo:<40} {total_loss:<20} {total_mse:<20} {total_kld:<20}\")\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Latent features for all data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z_mean_all = []\n",
    "        for batch_data, batch_lengths in tqdm(full_loader, desc=\"Extracting latent features\", leave=False):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_lengths = batch_lengths.to(device)\n",
    "\n",
    "            z_mean, _ = model.encoder(batch_data, batch_lengths)\n",
    "            z_mean_all.append(z_mean.cpu().numpy())\n",
    "        \n",
    "        latent_features = np.concatenate(z_mean_all, axis=0)\n",
    "    print(\"Latent features extracted for final VAE\")\n",
    "    return latent_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3058a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster_and_classify(latent_features, dbscan_eps, dbscan_min_samples, knn_n_neighbors):\n",
    "    dbscan = DBSCAN(eps=dbscan_eps, min_samples=dbscan_min_samples)\n",
    "    clusters = dbscan.fit_predict(latent_features)\n",
    "    outlier_mask = clusters == -1\n",
    "    binary_labels = (dbscan.labels_ != -1).astype(int)\n",
    "    print(\"DBSCAN Clustering Completed\")\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=knn_n_neighbors, weights='distance', metric='euclidean', algorithm='auto')\n",
    "    knn.fit(latent_features, binary_labels)\n",
    "    print(\"KNN Classifier Trained\")\n",
    "\n",
    "    del dbscan\n",
    "    return knn, clusters, outlier_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "217a63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iterative_vae_pipeline(\n",
    "    train_dataset: Dataset,\n",
    "    n_iterations: int = 5,\n",
    "    n_epochs_per_iter: int = 50,\n",
    "    batch_size: int = 32,\n",
    "    kde_percentile_rate: float = 0.05,\n",
    "    dbscan_eps: float = 0.5,\n",
    "    dbscan_min_samples: int = 5,\n",
    "    knn_n_neighbors: int = 5,\n",
    "    device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ") -> dict:\n",
    "    \n",
    "    # Model parameters\n",
    "    sample_data, _ = train_dataset[0]\n",
    "    print(\"Sample data shape:\", sample_data.shape)\n",
    "    input_dim = sample_data.shape[-1]\n",
    "    print(\"Input dim:\", input_dim)\n",
    "    hidden_dim = 16\n",
    "    latent_dim = 8\n",
    "    lstm_layers = 1\n",
    "\n",
    "    # Good and bad health indices initialization & model storage\n",
    "    valid_indices = list(range(len(train_dataset)))\n",
    "    all_anomaly_indices = np.array([], dtype=int)\n",
    "    vae_models = []\n",
    "\n",
    "    full_loader = DataLoader(dataset=train_dataset, \n",
    "                             batch_size=batch_size, \n",
    "                             shuffle=True, \n",
    "                             collate_fn=pad_sequences_smartly, \n",
    "                             drop_last=False,\n",
    "                             pin_memory=False,\n",
    "                             num_workers=0)\n",
    "\n",
    "    for iteration in range(n_iterations):\n",
    "        print(f\"\\nIteration {iteration + 1}/{n_iterations}\")\n",
    "        print(f\"Training on {len(valid_indices)} samples...\")\n",
    "\n",
    "        # Data SubSet creation\n",
    "        current_subset = Subset(train_dataset, valid_indices)\n",
    "        train_loader = DataLoader(dataset=current_subset, \n",
    "                                  batch_size=batch_size, \n",
    "                                  shuffle=True, \n",
    "                                  collate_fn=pad_sequences_smartly, \n",
    "                                  drop_last=False, \n",
    "                                  pin_memory=False,\n",
    "                                  num_workers=0)\n",
    "\n",
    "        # VAE Training\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        vae = LSTMBetaVAE(input_dim, hidden_dim, latent_dim, lstm_layers).to(device)\n",
    "        optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "        reconstruction_errors = train_one_vae(vae, optimizer, train_loader, full_loader, n_epochs_per_iter, device, verbose=True)\n",
    "\n",
    "        # Outlier detection with KDE\n",
    "        outlier_indices, threshold = detect_outliers_kde(reconstruction_errors, alpha=kde_percentile_rate)\n",
    "\n",
    "        # Update anomaly indices\n",
    "        all_anomaly_indices = np.unique(np.concatenate([all_anomaly_indices, outlier_indices]))\n",
    "        valid_indices = list(np.setdiff1d(np.arange(len(train_dataset)), all_anomaly_indices))\n",
    "        \n",
    "        vae_models.append(vae.state_dict())\n",
    "        print(f\"New anomalies detected: {len(outlier_indices)}\")\n",
    "        print(f\"Total anomalies: {len(all_anomaly_indices)}\\n\")\n",
    "\n",
    "        # Delete cache and big variables\n",
    "        del vae, optimizer, reconstruction_errors, current_subset, train_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "    # Last training phase\n",
    "    print(\"Training final model...\")\n",
    "    final_subset = Subset(train_dataset, valid_indices)\n",
    "    final_loader = DataLoader(final_subset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True, \n",
    "                              collate_fn=pad_sequences_smartly, \n",
    "                              drop_last=False, \n",
    "                              pin_memory=False, \n",
    "                              num_workers=0)\n",
    "\n",
    "    final_vae = LSTMBetaVAE(input_dim, hidden_dim, latent_dim, lstm_layers).to(device)\n",
    "    optimizer = torch.optim.Adam(final_vae.parameters(), lr=1e-3)\n",
    "\n",
    "    latent_features = train_final_vae(final_vae, optimizer, final_loader, full_loader, n_epochs_per_iter, device, verbose=True)\n",
    "\n",
    "    # Final clustering on latent space on all train_dataset, with DBScan coupled with KNN\n",
    "    knn, clusters, outlier_mask = find_cluster_and_classify(latent_features, dbscan_eps, dbscan_min_samples, knn_n_neighbors)\n",
    "\n",
    "    del final_loader, final_subset, full_loader\n",
    "    gc.collect()\n",
    "    return {\n",
    "        'final_vae': final_vae,\n",
    "        'vae_models': vae_models,\n",
    "        'knn': knn,\n",
    "        'anomaly_indices': all_anomaly_indices,\n",
    "        'latent_features': latent_features,\n",
    "        'clusters': clusters,\n",
    "        'outlier_mask': outlier_mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a017003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data shape: (174, 1)\n",
      "Input dim: 1\n",
      "\n",
      "Iteration 1/1\n",
      "Training on 4588 samples...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m knn_n_neighbors = \u001b[32m10\u001b[39m\n\u001b[32m      8\u001b[39m device = config.DEVICE\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m results = \u001b[43mtrain_iterative_vae_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_epochs_per_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_epochs_per_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkde_percentile_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkde_percentile_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdbscan_eps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdbscan_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdbscan_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdbscan_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mknn_n_neighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mknn_n_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mtrain_iterative_vae_pipeline\u001b[39m\u001b[34m(train_dataset, n_iterations, n_epochs_per_iter, batch_size, kde_percentile_rate, dbscan_eps, dbscan_min_samples, knn_n_neighbors, device)\u001b[39m\n\u001b[32m     50\u001b[39m gc.collect()\n\u001b[32m     51\u001b[39m torch.cuda.empty_cache()\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m vae = \u001b[43mLSTMBetaVAE\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_layers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m optimizer = torch.optim.Adam(vae.parameters(), lr=\u001b[32m1e-3\u001b[39m)\n\u001b[32m     55\u001b[39m reconstruction_errors = train_one_vae(vae, optimizer, train_loader, full_loader, n_epochs_per_iter, device, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1174\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1171\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    779\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m780\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    784\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    785\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    790\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    791\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:780\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    779\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m780\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    784\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    785\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    790\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    791\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:223\u001b[39m, in \u001b[36mRNNBase._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, recurse=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    222\u001b[39m     \u001b[38;5;28mself\u001b[39m._flat_weight_refs = []\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     ret = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m     \u001b[38;5;66;03m# Resets _flat_weights\u001b[39;00m\n\u001b[32m    226\u001b[39m     \u001b[38;5;66;03m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_flat_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:805\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    803\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m805\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    806\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    808\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ITER-magnetics-diagnostic-analysis/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1154\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1155\u001b[39m             device,\n\u001b[32m   1156\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1157\u001b[39m             non_blocking,\n\u001b[32m   1158\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1159\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 1\n",
    "n_epochs_per_iter = 2\n",
    "batch_size = 1\n",
    "kde_percentile_rate = 0.05\n",
    "dbscan_eps = 0.5\n",
    "dbscan_min_samples = 5\n",
    "knn_n_neighbors = 10\n",
    "device = config.DEVICE\n",
    "\n",
    "results = train_iterative_vae_pipeline(\n",
    "    train_dataset=train_set,\n",
    "    n_iterations=n_iterations,\n",
    "    n_epochs_per_iter=n_epochs_per_iter,\n",
    "    batch_size=batch_size,\n",
    "    kde_percentile_rate=kde_percentile_rate,\n",
    "    dbscan_eps=dbscan_eps,\n",
    "    dbscan_min_samples=dbscan_min_samples,\n",
    "    knn_n_neighbors=knn_n_neighbors,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aac6a735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mémoire GPU allouée: 0.00 MB\n",
      "Mémoire GPU réservée: 0.00 MB\n",
      "Mémoire GPU totale: 14.58 GB\n",
      "Mémoire GPU disponible: 14.58 GB\n"
     ]
    }
   ],
   "source": [
    "def check_memory_usage():\n",
    "    print(f\"Mémoire GPU allouée: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "    print(f\"Mémoire GPU réservée: {torch.cuda.memory_reserved() / 1024**2:.2f} MB\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Mémoire GPU totale: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"Mémoire GPU disponible: {torch.cuda.get_device_properties(0).total_memory / 1024**3 - torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "check_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d9fb6cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m final_vae = \u001b[43mresults\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mfinal_vae\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      2\u001b[39m knn = results[\u001b[33m'\u001b[39m\u001b[33mknn\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "final_vae = results['final_vae']\n",
    "knn = results['knn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64267c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d087274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(test_dataset, trained_vae, device):\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_dataset, \n",
    "        batch_size=32, \n",
    "        shuffle=False, \n",
    "        collate_fn=pad_sequences_smartly, \n",
    "        drop_last=False\n",
    "    )\n",
    "    trained_vae.eval()\n",
    "    \n",
    "    reconstruction_errors = []\n",
    "    latent_features = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_lengths in test_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_lengths = batch_lengths.to(device)\n",
    "            \n",
    "            recon_batch, z_mean, _ = trained_vae(batch_data, batch_lengths)\n",
    "            # Store latent features\n",
    "            latent_features.append(z_mean.cpu().numpy())\n",
    "\n",
    "            mse = vae_reconstruction_error(recon_batch, batch_data, batch_lengths)\n",
    "            # Store reconstruction errors\n",
    "            reconstruction_errors.extend(mse.cpu().numpy())\n",
    "    \n",
    "    return np.array(reconstruction_errors), np.concatenate(latent_features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca924ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda6cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b6e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_time(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    n_epochs: int,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device\n",
    "):\n",
    "    current_data = data.copy()\n",
    "    anomaly_indices = np.array([], dtype=int)\n",
    "\n",
    "    reconstruction_error_threshold_percentile = 95\n",
    "\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            data, lengths = batch\n",
    "            data = data.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data, lengths)\n",
    "            loss = criterion(output, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8173b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_iterations: int):\n",
    "    for i in range(n_iterations):\n",
    "        model = VAE()\n",
    "        train_one_time(model, train_loader, n_epochs, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868180fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5b839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b925fc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c850977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITER-magnetics-diagnostic-analysis (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

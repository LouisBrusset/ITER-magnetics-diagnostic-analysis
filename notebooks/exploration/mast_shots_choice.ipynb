{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af15f00",
   "metadata": {},
   "source": [
    "# Choice of MAST shots to load for scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57266e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import pathlib\n",
    "import tqdm\n",
    "from functools import partial\n",
    "import os\n",
    "import psutil\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0d45d8",
   "metadata": {},
   "source": [
    "## Selection of shot_index and variable_channels with no NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d3a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dask(shot: int, group: str, level: int = 2) -> xr.Dataset:\n",
    "    \"\"\"\n",
    "    Return a Dataset from the MAST Zarr store.\n",
    "\n",
    "    Parameters\n",
    "    shot: Shot ID to retrieve data for.\n",
    "    group: Diagnostic group to retrieve data from.\n",
    "    level: Data level to retrieve (default is 2).\n",
    "    \"\"\"\n",
    "    return xr.open_zarr(\n",
    "        f\"https://s3.echo.stfc.ac.uk/mast/level{level}/shots/{shot}.zarr\",\n",
    "        group=group,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry_to_dask(shot_id, group, retries=3, delay=1):\n",
    "    \"\"\"\n",
    "    Retry loading a shot's data as a Dask Dataset with exponential backoff.\n",
    "\n",
    "    Parameters\n",
    "    shot_id: Shot ID to retrieve data for.\n",
    "    group: Diagnostic group to retrieve data from.\n",
    "    retries: Number of retry attempts (default is 3).\n",
    "    delay: Delay in seconds between retries (default is 5).\n",
    "\n",
    "    Returns\n",
    "    xr.Dataset\n",
    "        The Dask Dataset for the specified shot and group.\n",
    "    or Error\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            return to_dask(shot_id, group)\n",
    "        except Exception as e:\n",
    "            if attempt < retries - 1:\n",
    "                print(f\"Retrying connection to {shot_id} in group {group} (attempt {attempt + 1}/{retries})\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_shot(shot_id, group, verbose=False):\n",
    "    \"\"\"\n",
    "    Process a single shot, returning a dictionary of results.\n",
    "\n",
    "    Parameters\n",
    "    shot_id: Shot ID to retrieve data for.\n",
    "    group: Diagnostic group to retrieve data from.\n",
    "    verbose: bool\n",
    "        Displays messages for debugging or tracking.\n",
    "    \n",
    "    Returns\n",
    "    shot_id: int\n",
    "        The shot ID processed.\n",
    "    shot_result: dict\n",
    "        Dictionary containing the presence of variables and their channels:\n",
    "    \"\"\"\n",
    "    shot_result = {}\n",
    "    try:\n",
    "        ds = retry_to_dask(shot_id, group)\n",
    "        shot_vars = set(ds.data_vars)\n",
    "\n",
    "        for var in shot_vars:\n",
    "            da = ds[var]\n",
    "            time_dims = [dim for dim in da.dims if 'time' in dim.lower()]\n",
    "            \n",
    "            if not time_dims:\n",
    "                if verbose:\n",
    "                    print(f\"Skipping {var} with no time dimension: {da.dims}\")\n",
    "                continue\n",
    "            \n",
    "            time_dim = time_dims[0]\n",
    "            other_dims = [dim for dim in da.dims if dim != time_dim]\n",
    "\n",
    "            # 1. Variable 1D\n",
    "            if not other_dims:\n",
    "                key = var\n",
    "                try:\n",
    "                    if np.issubdtype(da.dtype, np.floating):\n",
    "                        has_valid = da.notnull().any().compute()\n",
    "                        shot_result[key] = True if has_valid else None\n",
    "                    else:\n",
    "                        # For non-floating types, we assume presence if the variable exists.\n",
    "                        shot_result[key] = True\n",
    "                except Exception as e:\n",
    "                    if verbose:\n",
    "                        print(f\"Error processing {var} in shot {shot_id}: {e}\")\n",
    "                    shot_result[key] = False\n",
    "\n",
    "            # 2. Variable 2D\n",
    "            else:\n",
    "                for dim in other_dims:\n",
    "                    if dim not in ds.coords:\n",
    "                        if verbose:\n",
    "                            print(f\"Warning: {dim} not found for {var} in shot {shot_id}\")\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        if np.issubdtype(da.dtype, np.floating):\n",
    "                            channel_has_data = da.notnull().any(dim=time_dim)\n",
    "                        else:\n",
    "                            # For non-floating types, we assume presence if the variable exists.\n",
    "                            channel_has_data = xr.ones_like(ds[dim], dtype=bool)\n",
    "                        \n",
    "                        channel_results = channel_has_data.compute()\n",
    "                        \n",
    "                        for coord_val in ds[dim].values:\n",
    "                            key = f\"{var}::{coord_val}\"\n",
    "                            try:\n",
    "                                chan_valid = channel_results.sel({dim: coord_val}).item()\n",
    "                                shot_result[key] = True if chan_valid else None\n",
    "                            except Exception as e:\n",
    "                                if verbose:\n",
    "                                    print(f\"Error accessing {coord_val} in {var}: {e}\")\n",
    "                                shot_result[key] = False\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        if verbose:\n",
    "                            print(f\"Error processing {var} in shot {shot_id}: {e}\")\n",
    "                        for coord_val in ds[dim].values:\n",
    "                            key = f\"{var}::{coord_val}\"\n",
    "                            shot_result[key] = False\n",
    "\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error processing shot {shot_id}: {e}\")\n",
    "        shot_result = {}\n",
    "\n",
    "    return shot_id, shot_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_workers(task_type=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Get the optimal number of workers for parallel processing based on the task type.\n",
    "\n",
    "    Parameters\n",
    "    task_type: str\n",
    "        Type of task to determine the optimal number of workers (only possibility is \"cpu\").\n",
    "\n",
    "    Returns the optimal number of workers based on the task type.\n",
    "    \"\"\"\n",
    "    cpu_logical = os.cpu_count()\n",
    "    \n",
    "    if task_type == \"cpu\":\n",
    "        try:\n",
    "            return psutil.cpu_count(logical=False)\n",
    "        except:\n",
    "            return max(1, cpu_logical // 2)  # Default to half of logical cores\n",
    "    else:\n",
    "        return max(1, cpu_logical - 1) # Default to one less than logical cores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79768f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variable_presence_parallel(\n",
    "    shots: list[int],\n",
    "    group: str,\n",
    "    verbose: bool = False,\n",
    "    max_workers: int = None\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Parallelized version with ThreadPoolExecutor.\n",
    "    Check presence of all variables (and their channels) across shots in a group.\n",
    "\n",
    "    Parameters\n",
    "    shots: list of int\n",
    "        List of shot IDs to be processed.\n",
    "    group: str\n",
    "        Diagnostic group to which the variable belongs (e.g., “magnetics,” “summary,” etc.).\n",
    "    verbose: bool\n",
    "        Displays messages for debugging or tracking.\n",
    "    max_workers: int, optional\n",
    "        Maximum number of workers to use for parallel processing. If None, uses an optimal value based on get_optimal_worker.\n",
    "    \"\"\"\n",
    "    if max_workers is None:\n",
    "        max_workers = get_optimal_workers()\n",
    "    print(f\"Use of {max_workers} workers (type: cpu)\")\n",
    "    \n",
    "    var_presence = {}\n",
    "    seen_shots = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for shot_id in shots:\n",
    "            futures.append(executor.submit(partial(process_shot, group=group, verbose=verbose), shot_id))\n",
    "        \n",
    "        for future in tqdm.tqdm(\n",
    "            concurrent.futures.as_completed(futures),\n",
    "            total=len(shots),\n",
    "            desc=\"Checking variables (parallel)\"\n",
    "        ):\n",
    "            shot_id, shot_result = future.result()\n",
    "            seen_shots.append(shot_id)\n",
    "            \n",
    "            for key, present in shot_result.items():\n",
    "                if key not in var_presence:\n",
    "                    var_presence[key] = {s: False for s in seen_shots}\n",
    "                var_presence[key][shot_id] = present\n",
    "            \n",
    "            # Mark missing variables/channels as False: case where there was a \"continue\" in process_shot.\n",
    "            for key in var_presence:\n",
    "                if shot_id not in var_presence[key]:\n",
    "                    var_presence[key][shot_id] = False\n",
    "\n",
    "    df = pd.DataFrame(var_presence).T\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00476c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://mastapp.site'\n",
    "shots_disappearance = pd.read_parquet(f'{URL}/parquet/level2/shots')\n",
    "sorted_disappearance = shots_disappearance.sort_values(\"timestamp\")\n",
    "shots = sorted_disappearance['shot_id'].tolist()\n",
    "print(\"Number of shots: \", len(shots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea9982",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'magnetics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_presence_all = check_variable_presence_parallel(\n",
    "    shots=shots, \n",
    "    group=group, \n",
    "    verbose=True,\n",
    "    max_workers=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbb4e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"notebooks/result_files/all_shots_{group}\"\n",
    "path = pathlib.Path().absolute().parent.parent.parent / file_path / f\"variable_presence_all_shots_{group}.csv\"\n",
    "variable_presence_all.to_csv(path, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd94e45",
   "metadata": {},
   "source": [
    "#### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2fa12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of variable presence\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def plot_variable_presence(variable_presence_all: pd.DataFrame, plot: bool = True, register: bool = False, register_path: str = \"foo.png\") -> None:\n",
    "    \"\"\"\n",
    "    Plot the presence of variables across all shots in a group.\n",
    "\n",
    "    Parameters\n",
    "    variable_presence_all: pd.DataFrame\n",
    "        DataFrame with variable presence across shots.\n",
    "    group: str\n",
    "        Diagnostic group name (e.g., \"magnetics\").\n",
    "    plot: bool\n",
    "        If True, display the plot.\n",
    "    register: bool\n",
    "        If True, save the plot to a file.\n",
    "    register_name: str\n",
    "        Name of the file to save the plot (if register is True).\n",
    "\n",
    "    Returns\n",
    "    None    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an integer matrix for colormapping: 0 = False, 1 = True\n",
    "    plot_df = variable_presence_all.fillna(False).infer_objects(copy=False)\n",
    "    plot_matrix = plot_df.to_numpy()\n",
    "    int_matrix = plot_matrix.astype(int)\n",
    "\n",
    "    # Dimensions\n",
    "    n_vars, n_shots = int_matrix.shape\n",
    "\n",
    "    # Colors: 0 = red, 1 = green\n",
    "    cmap = ListedColormap([\"#4caf50\", \"#f44336\"])  # green for True, red for False\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(n_shots * 0.01, max(16, n_vars * 0.25)))\n",
    "    im = ax.imshow(~int_matrix, aspect='auto', cmap=cmap, interpolation='none')\n",
    "\n",
    "\n",
    "    ax.set_yticks(np.arange(n_vars))\n",
    "    ax.set_yticklabels(variable_presence_all.index)\n",
    "    ax.set_xticks(np.linspace(0, n_shots - 1, min(n_shots, 1000), dtype=int))\n",
    "    ax.set_xticklabels([variable_presence_all.columns[i] for i in np.linspace(0, n_shots - 1, min(n_shots, 1000), dtype=int)], rotation=90)\n",
    "    ax.set_xlabel(\"Shot ID\")\n",
    "    ax.set_ylabel(\"Variable::Channel\")\n",
    "    ax.set_title(\"Variable Presence Across Shots (green = present, red = missing)\")\n",
    "    ax.grid(False, axis='x')\n",
    "    ax.set_yticks(np.arange(n_vars + 1) - 0.5, minor=True)\n",
    "    ax.grid(True, axis='y', which='minor', color='gray', linestyle='--')\n",
    "\n",
    "    if register:\n",
    "        plt.savefig(register_path, dpi=\"figure\")\n",
    "        print(f\"Plot saved to {register_path}\")\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    fig.close()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc406a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_path = pathlib.Path().absolute().parent.parent.parent / \"results/figures\" / f\"variable_presence_{group}.png\"\n",
    "plot_variable_presence(variable_presence_all, plot=True, register=True, register_path=register_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f06cf9",
   "metadata": {},
   "source": [
    "## Selection of shots and variable channels in good health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variable_presence_all(path: str, group: str = group, shot_threshold: float = 0.99, var_threshold: float = 0.8) -> list:\n",
    "    \"\"\"\n",
    "    Select the good shots and variables::channels to avoid the presence of too many NaNs in the dataset.\n",
    "\n",
    "    Parameters\n",
    "    path: str\n",
    "        Path to the CSV file containing variable presence data.\n",
    "\n",
    "    Returns\n",
    "    list(\n",
    "        good_shots: list of shot IDs that are present in enough variables.\n",
    "        bad_shots: list of shot IDs that are missing too many variables.\n",
    "        good_vars: list of variable::channel names that are present in enough shots.\n",
    "        bad_vars: list of variable::channel names that are missing too many shots.)\n",
    "    \"\"\"\n",
    "    # Load the variable presence DataFrame\n",
    "    path = pathlib.Path().absolute().parent.parent.parent / path\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df = df.fillna(False).infer_objects(copy=False)\n",
    "\n",
    "    # Then delete the variables::channels for which at least 50% of the content is True. And store them in an array.\n",
    "    bad_vars = df.index[df.sum(axis=1) < (len(df.columns) * var_threshold)].tolist()\n",
    "    df = df.drop(index=bad_vars)\n",
    "    plot_variable_presence(df, group=group, plot=True, register=False)\n",
    "\n",
    "    # First delete the shots for which all variables are False. And store them in an array.\n",
    "    bad_shots = df.columns[df.sum(axis=0) < (len(df.index) * shot_threshold)].tolist()\n",
    "    df = df.drop(columns=bad_shots)\n",
    "    plot_variable_presence(df, group=group, plot=True, register=True, register_name=f'variable_presence_{group}_filtered.png')\n",
    "\n",
    "\n",
    "    return [\n",
    "        df.columns.tolist(),    # Good shots\n",
    "        bad_shots,              # Bad shots\n",
    "        df.index.tolist(),      # Good variables::channels\n",
    "        bad_vars                # Bad variables::channels\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2fe5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_shot_ids, bad_shot_ids, good_vars_ids, bad_vars_ids = check_variable_presence_all(\n",
    "    path=f\"notebooks/result_files/all_shots_{group}/variable_presence_all_shots_{group}.csv\",\n",
    "    group=group,\n",
    "    shot_threshold=0.99,\n",
    "    var_threshold=0.8)\n",
    "\n",
    "print(f\"Number of bad variable::channel IDs: {len(bad_vars_ids)}\")\n",
    "print(\"Bad variable::channel IDs:\", bad_vars_ids[:25])\n",
    "\n",
    "print(f\"Number of bad shot IDs: {len(bad_shot_ids)}\")\n",
    "print(\"Bad shot IDs:\", bad_shot_ids[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"good_shot_ids\": good_shot_ids,\n",
    "    \"bad_shot_ids\": bad_shot_ids,\n",
    "    \"goobad_vars_ids\": good_vars_ids,\n",
    "    \"bad_vars_ids\": bad_vars_ids,\n",
    "}\n",
    "\n",
    "path = pathlib.Path().absolute().parent.parent.parent / f\"notebooks/result_files/all_shots_{group}\"\n",
    "file_name = path / f\"result_lists{group}.json\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITER-magnetics-diagnostic-analysis (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
